{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ec413ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df138b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.append.AppendableIndex at 0x7be7c0ea6a40>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from minsearch import AppendableIndex\n",
    "\n",
    "index = AppendableIndex(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")\n",
    "\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94a60573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5,\n",
    "        output_ids=True\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "507a0583",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<CONTEXT>\n",
    "{context}\n",
    "</CONTEXT>\n",
    "\"\"\".strip()\n",
    "\n",
    "def build_prompt(query, search_results):\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93e2be7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Cargar .env\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09505649",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5713e846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To join the course, you need to register before the course starts using the provided link. The course will commence on January 15, 2024, at 17h00, and you can also join the course Telegram channel for announcements and register in DataTalks.Club's Slack to join the channel. Even if you miss the registration before the start date, you can still submit homework assignments, but be mindful of deadlines for final projects.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'how do i join the course?'\n",
    "rag(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "764d83c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant.\n",
    "\n",
    "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
    "At the beginning the context is EMPTY.\n",
    "\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<CONTEXT> \n",
    "{context}\n",
    "</CONTEXT>\n",
    "\n",
    "IF you have an acceptable response, proceed to answer, or If CONTEXT is EMPTY and you dont have an accurate answer, you SHOULD use our FAQ database.\n",
    "In this case, use the following output template:\n",
    "\n",
    "{{\n",
    "\"action\": \"SEARCH\",\n",
    "\"reasoning\": \"<add your reasoning here>\"\n",
    "}}\n",
    "\n",
    "If you can answer the QUESTION using CONTEXT, use this template:\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"CONTEXT\"\n",
    "}}\n",
    "\n",
    "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"OWN_KNOWLEDGE\"\n",
    "}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a0a5ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "At the beginning the context is EMPTY.\n",
      "\n",
      "<QUESTION>\n",
      "how do I run docker on gentoo?\n",
      "</QUESTION>\n",
      "\n",
      "<CONTEXT> \n",
      "EMPTY\n",
      "</CONTEXT>\n",
      "\n",
      "IF you have an acceptable response, proceed to answer, or If CONTEXT is EMPTY and you dont have an accurate answer, you SHOULD use our FAQ database.\n",
      "In this case, use the following output template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\"\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"To run Docker on Gentoo, you will need to install the package `app-containers/docker`. Here are the steps you can follow:\\n\\n1. **Update the Portage tree**: Make sure your Portage tree is up to date by running:\\n   ```bash\\n   emerge --sync\\n   ```\\n\\n2. **Install Docker**: You can install Docker using the following command:\\n   ```bash\\n   emerge app-containers/docker\\n   ```\\n\\n3. **Add your user to the docker group**: This allows you to run Docker commands without sudo:\\n   ```bash\\n   usermod -aG docker $USER\\n   ```\\n   Log out and back in for the group changes to take effect.\\n\\n4. **Start the Docker service**: You can manage the Docker service using OpenRC:\\n   ```bash\\n   rc-update add docker default\\n   service docker start\\n   ```\\n\\n5. **Verify the installation**: You can run a simple Docker command to verify that it's working:\\n   ```bash\\n   docker run hello-world\\n   ```\\n\\nIf you want to configure Docker further or use it with a graphical interface, you may need additional configurations. Documentation specific to Gentoo can also be helpful for advanced setups.\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "question = \"how do I run docker on gentoo?\"\n",
    "context = \"EMPTY\"\n",
    "\n",
    "prompt = prompt_template.format(question=question, context=context)\n",
    "print(prompt)\n",
    "\n",
    "answer = llm(prompt)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5191aa7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"The context is empty, and I don't have specific information about how to join the course.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "question = \"how do I join the course?\"\n",
    "context = \"EMPTY\"\n",
    "\n",
    "prompt = prompt_template.format(question=question, context=context)\n",
    "answer = llm(prompt)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "192cca17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_context(search_results):\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "\n",
    "    return context.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcaefd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "At the beginning the context is EMPTY.\n",
      "\n",
      "<QUESTION>\n",
      "how do I join the course?\n",
      "</QUESTION>\n",
      "\n",
      "<CONTEXT> \n",
      "section: General course-related questions\n",
      "question: Course - Can I still join the course after the start date?\n",
      "answer: Yes, even if you don't register, you're still eligible to submit the homeworks.\n",
      "Be aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - When will the course start?\n",
      "answer: The purpose of this document is to capture frequently asked technical questions\n",
      "The exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\n",
      "Subscribe to course public Google Calendar (it works from Desktop only).\n",
      "Register before the course starts using this link.\n",
      "Join the course Telegram channel with announcements.\n",
      "Don’t forget to register in DataTalks.Club's Slack and join the channel.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - Can I follow the course after it finishes?\n",
      "answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\n",
      "You can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Certificate - Can I follow the course in a self-paced mode and get a certificate?\n",
      "answer: No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\n",
      "\n",
      "section: General course-related questions\n",
      "question: How do I use Git / GitHub for this course?\n",
      "answer: After you create a GitHub account, you should clone the course repo to your local machine using the process outlined in this video: Git for Everybody: How to Clone a Repository from GitHub\n",
      "Having this local repository on your computer will make it easy for you to access the instructors’ code and make pull requests (if you want to add your own notes or make changes to the course content).\n",
      "You will probably also create your own repositories that host your notes, versions of your file, to do this. Here is a great tutorial that shows you how to do this: https://www.atlassian.com/git/tutorials/setting-up-a-repository\n",
      "Remember to ignore large database, .csv, and .gz files, and other files that should not be saved to a repository. Use .gitignore for this: https://www.atlassian.com/git/tutorials/saving-changes/gitignore NEVER store passwords or keys in a git repo (even if that repo is set to private).\n",
      "This is also a great resource: https://dangitgit.com/\n",
      "</CONTEXT>\n",
      "\n",
      "IF you have an acceptable response, proceed to answer, or If CONTEXT is EMPTY and you dont have an accurate answer, you SHOULD use our FAQ database.\n",
      "In this case, use the following output template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\"\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "search_results = search(question)\n",
    "context = build_context(search_results)\n",
    "prompt = prompt_template.format(question=question, context=context)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d360e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"To join the course, you should register before the course starts using the provided registration link. Additionally, make sure to join the course Telegram channel for announcements and subscribe to the course public Google Calendar for updates. The course starts on January 15, 2024, at 17h00 with the first 'Office Hours' live session. Even if you miss registration, you can still submit homework assignments.\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "answer = llm(prompt)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "899de870",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77eeba4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agentic_rag_v1(question):\n",
    "    context = \"EMPTY\"\n",
    "    prompt = prompt_template.format(question=question, context=context)\n",
    "    answer_json = llm(prompt)\n",
    "    answer = json.loads(answer_json)\n",
    "    print(answer)\n",
    "\n",
    "    if answer['action'] == 'SEARCH':\n",
    "        print('need to perform search...')\n",
    "        search_results = search(question)\n",
    "        context = build_context(search_results)\n",
    "        \n",
    "        prompt = prompt_template.format(question=question, context=context)\n",
    "        answer_json = llm(prompt)\n",
    "        answer = json.loads(answer_json)\n",
    "        print(answer)\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "182fcbbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action': 'SEARCH', 'reasoning': 'The context is empty and I need specific information about how to join the course, which I do not have.'}\n",
      "need to perform search...\n",
      "{'action': 'ANSWER', 'answer': \"To join the course, you need to register using the link provided in the course materials before the course starts. The course will officially begin on January 15, 2024, at 17h00. Additionally, it is recommended to join the course Telegram channel for announcements and to register in DataTalks.Club's Slack to stay connected with other participants and instructors.\", 'source': 'CONTEXT'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'action': 'ANSWER',\n",
       " 'answer': \"To join the course, you need to register using the link provided in the course materials before the course starts. The course will officially begin on January 15, 2024, at 17h00. Additionally, it is recommended to join the course Telegram channel for announcements and to register in DataTalks.Club's Slack to stay connected with other participants and instructors.\",\n",
       " 'source': 'CONTEXT'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agentic_rag_v1('how do I join the course?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1924b4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action': 'ANSWER', 'answer': \"To patch KDE under FreeBSD, you can follow these steps:\\n\\n1. **Install the necessary tools**: Make sure you have installed 'patch' and 'diff' tools, which are typically included in FreeBSD. You can check if they're installed by running `patch --version` and `diff --version` in the terminal.\\n   \\n2. **Download the patch**: Obtain the relevant patch file you want to apply. This might be from a bug report or a specific repository.\\n   \\n3. **Navigate to the source directory**: Use the terminal to navigate to the directory containing the KDE source code that you want to patch. For example, this might be located in `/usr/ports/x11/kde5` or wherever the source is stored.\\n   \\n4. **Apply the patch**: Run the command `patch -p1 < /path/to/your/patchfile.patch` to apply the patch. The `-p1` option tells `patch` how to strip the directory path from the filenames in the patch.\\n   \\n5. **Compile and install KDE**: After applying the patch, you will likely need to rebuild KDE. You can do this with the relevant FreeBSD port command, such as `make install clean` within the KDE source directory. \\n   \\n6. **Test the changes**: After installation, test KDE to ensure that the changes from the patch have been applied correctly and that everything is functioning as expected.\\n   \\nRemember to backup any important data before making changes, and consult the FreeBSD and KDE documentation for any specific details related to patches or build customizations.\\n\", 'source': 'OWN_KNOWLEDGE'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'action': 'ANSWER',\n",
       " 'answer': \"To patch KDE under FreeBSD, you can follow these steps:\\n\\n1. **Install the necessary tools**: Make sure you have installed 'patch' and 'diff' tools, which are typically included in FreeBSD. You can check if they're installed by running `patch --version` and `diff --version` in the terminal.\\n   \\n2. **Download the patch**: Obtain the relevant patch file you want to apply. This might be from a bug report or a specific repository.\\n   \\n3. **Navigate to the source directory**: Use the terminal to navigate to the directory containing the KDE source code that you want to patch. For example, this might be located in `/usr/ports/x11/kde5` or wherever the source is stored.\\n   \\n4. **Apply the patch**: Run the command `patch -p1 < /path/to/your/patchfile.patch` to apply the patch. The `-p1` option tells `patch` how to strip the directory path from the filenames in the patch.\\n   \\n5. **Compile and install KDE**: After applying the patch, you will likely need to rebuild KDE. You can do this with the relevant FreeBSD port command, such as `make install clean` within the KDE source directory. \\n   \\n6. **Test the changes**: After installation, test KDE to ensure that the changes from the patch have been applied correctly and that everything is functioning as expected.\\n   \\nRemember to backup any important data before making changes, and consult the FreeBSD and KDE documentation for any specific details related to patches or build customizations.\\n\",\n",
       " 'source': 'OWN_KNOWLEDGE'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agentic_rag_v1('how patch KDE under FreeBSD?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20df7eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant.\n",
    "\n",
    "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
    "\n",
    "The CONTEXT is build with the documents from our FAQ database.\n",
    "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
    "from FAQ to and add them to the context.\n",
    "PREVIOUS_ACTIONS contains the actions you already performed.\n",
    "\n",
    "At the beginning the CONTEXT is empty.\n",
    "\n",
    "You can perform the following actions:\n",
    "\n",
    "- Search in the FAQ database to get more data for the CONTEXT\n",
    "- Answer the question using the CONTEXT\n",
    "- Answer the question using your own knowledge\n",
    "\n",
    "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
    "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
    "\n",
    "Don't use search queries used at the previous iterations.\n",
    "\n",
    "Don't repeat previously performed actions.\n",
    "\n",
    "Don't perform more than {max_iterations} iterations for a given student question.\n",
    "The current iteration number: {iteration_number}. If we exceed the allowed number \n",
    "of iterations, give the best possible answer with the provided information.\n",
    "\n",
    "Output templates:\n",
    "\n",
    "If you want to perform search, use this template:\n",
    "\n",
    "{{\n",
    "\"action\": \"SEARCH\",\n",
    "\"reasoning\": \"<add your reasoning here>\",\n",
    "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
    "}}\n",
    "\n",
    "If you can answer the QUESTION using CONTEXT, use this template:\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER_CONTEXT\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"CONTEXT\"\n",
    "}}\n",
    "\n",
    "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"OWN_KNOWLEDGE\"\n",
    "}}\n",
    "\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<SEARCH_QUERIES>\n",
    "{search_queries}\n",
    "</SEARCH_QUERIES>\n",
    "\n",
    "<CONTEXT> \n",
    "{context}\n",
    "</CONTEXT>\n",
    "\n",
    "<PREVIOUS_ACTIONS>\n",
    "{previous_actions}\n",
    "</PREVIOUS_ACTIONS>\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0f0cb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 1. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "how do I join the course?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "\n",
      "</PREVIOUS_ACTIONS>\n"
     ]
    }
   ],
   "source": [
    "question = \"how do I join the course?\"\n",
    "\n",
    "search_queries = []\n",
    "search_results = []\n",
    "previous_actions = []\n",
    "context = build_context(search_results)\n",
    "\n",
    "prompt = prompt_template.format(\n",
    "    question=question,\n",
    "    context=context,\n",
    "    search_queries=\"\\n\".join(search_queries),\n",
    "    previous_actions='\\n'.join([json.dumps(a) for a in previous_actions]),\n",
    "    max_iterations=3,\n",
    "    iteration_number=1\n",
    ")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "327cd24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"action\": \"SEARCH\",\n",
      "  \"reasoning\": \"To provide accurate information on how to join the course, I need to look for relevant details in the FAQ database.\",\n",
      "  \"keywords\": [\n",
      "    \"how to join the course\",\n",
      "    \"enrollment process\",\n",
      "    \"course registration\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "answer_json = llm(prompt)\n",
    "answer = json.loads(answer_json)\n",
    "print(json.dumps(answer, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a949157f",
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_actions.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5390fd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = answer['keywords']\n",
    "search_queries.extend(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c11ba5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in keywords:\n",
    "    res = search(k)\n",
    "    search_results.extend(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e93323dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Can I still join the course after the start date?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 2},\n",
       " {'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - When will the course start?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 0},\n",
       " {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Can I follow the course after it finishes?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 7},\n",
       " {'text': \"No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Certificate - Can I follow the course in a self-paced mode and get a certificate?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 11},\n",
       " {'text': 'After you create a GitHub account, you should clone the course repo to your local machine using the process outlined in this video: Git for Everybody: How to Clone a Repository from GitHub\\nHaving this local repository on your computer will make it easy for you to access the instructors’ code and make pull requests (if you want to add your own notes or make changes to the course content).\\nYou will probably also create your own repositories that host your notes, versions of your file, to do this. Here is a great tutorial that shows you how to do this: https://www.atlassian.com/git/tutorials/setting-up-a-repository\\nRemember to ignore large database, .csv, and .gz files, and other files that should not be saved to a repository. Use .gitignore for this: https://www.atlassian.com/git/tutorials/saving-changes/gitignore NEVER store passwords or keys in a git repo (even if that repo is set to private).\\nThis is also a great resource: https://dangitgit.com/',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'How do I use Git / GitHub for this course?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 41},\n",
       " {'text': 'After installing all including pyspark (and it is successfully imported), but then running this script on the jupyter notebook\\nimport pyspark\\nfrom pyspark.sql import SparkSession\\nspark = SparkSession.builder \\\\\\n.master(\"local[*]\") \\\\\\n.appName(\\'test\\') \\\\\\n.getOrCreate()\\ndf = spark.read \\\\\\n.option(\"header\", \"true\") \\\\\\n.csv(\\'taxi+_zone_lookup.csv\\')\\ndf.show()\\nit gives the error:\\nRuntimeError: Java gateway process exited before sending its port number\\n✅The solution (for me) was:\\npip install findspark on the command line and then\\nAdd\\nimport findspark\\nfindspark.init()\\nto the top of the script.\\nAnother possible solution is:\\nCheck that pyspark is pointing to the correct location.\\nRun pyspark.__file__. It should be list /home/<your user name>/spark/spark-3.0.3-bin-hadoop3.2/python/pyspark/__init__.py if you followed the videos.\\nIf it is pointing to your python site-packages remove the pyspark directory there and check that you have added the correct exports to you .bashrc file and that there are not any other exports which might supersede the ones provided in the course content.\\nTo add to the solution above, if the errors persist in regards to setting the correct path for spark,  an alternative solution for permanent path setting solve the error is  to set environment variables on system and user environment variables following this tutorial: Install Apache PySpark on Windows PC | Apache Spark Installation Guide\\nOnce everything is installed, skip to 7:14 to set up environment variables. This allows for the environment variables to be set permanently.',\n",
       "  'section': 'Module 5: pyspark',\n",
       "  'question': 'lsRuntimeError: Java gateway process exited before sending its port number',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 321},\n",
       " {'text': 'pd.read_csv\\ndf_iter = pd.read_csv(dataset_url, iterator=True, chunksize=100000)\\nThe data needs to be appended to the parquet file using the fastparquet engine\\ndf.to_parquet(path, compression=\"gzip\", engine=\\'fastparquet\\', append=True)',\n",
       "  'section': 'Module 2: Workflow Orchestration',\n",
       "  'question': 'Process to download the VSC using Pandas is killed right away',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 178},\n",
       " {'text': \"For everyone who's having problem with Docker compose, getting the data in postgres and similar issues, please take care of the following:\\ncreate a new volume on docker (either using the command line or docker desktop app)\\nmake the following changes to your docker-compose.yml file (see attachment)\\nset low_memory=false when importing the csv file (df = pd.read_csv('yellow_tripdata_2021-01.csv', nrows=1000, low_memory=False))\\nuse the below function (in the upload-data.ipynb) for better tracking of your ingestion process (see attachment)\\nOrder of execution:\\n(1) open terminal in 2_docker_sql folder and run docker compose up\\n(2) ensure no other containers are running except the one you just executed (pgadmin and pgdatabase)\\n(3) open jupyter notebook and begin the data ingestion\\n(4) open pgadmin and set up a server (make sure you use the same configurations as your docker-compose.yml file like the same name (pgdatabase), port, databasename (ny_taxi) etc.\",\n",
       "  'section': 'Module 1: Docker and Terraform',\n",
       "  'question': 'Docker-Compose - Errors pertaining to docker-compose.yml and pgadmin setup',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 88},\n",
       " {'text': 'After you create a GitHub account, you should clone the course repo to your local machine using the process outlined in this video: Git for Everybody: How to Clone a Repository from GitHub\\nHaving this local repository on your computer will make it easy for you to access the instructors’ code and make pull requests (if you want to add your own notes or make changes to the course content).\\nYou will probably also create your own repositories that host your notes, versions of your file, to do this. Here is a great tutorial that shows you how to do this: https://www.atlassian.com/git/tutorials/setting-up-a-repository\\nRemember to ignore large database, .csv, and .gz files, and other files that should not be saved to a repository. Use .gitignore for this: https://www.atlassian.com/git/tutorials/saving-changes/gitignore NEVER store passwords or keys in a git repo (even if that repo is set to private).\\nThis is also a great resource: https://dangitgit.com/',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'How do I use Git / GitHub for this course?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 41},\n",
       " {'text': \"If you get the following error\\nYou have to edit variables.tf on the gcp folder, set your project-id and region and zones properly. Then, run terraform apply again.\\nYou can find correct regions/zones here: https://cloud.google.com/compute/docs/regions-zones\\nDeploying MAGE to GCP  with Terraform via the VM (2.2.7)\\nFYI - It can take up to 20 minutes to deploy the MAGE Terraform files if you are using a GCP Virtual Machine. It is normal, so don’t interrupt the process or think it’s taking too long. If you have, make sure you run a terraform destroy before trying again as you will have likely partially created resources which will cause errors next time you run `terraform apply`.\\n`terraform destroy` may not completely delete partial resources - go to Google Cloud Console and use the search bar at the top to search for the ‘app.name’ you declared in your variables.tf file; this will list all resources with that name - make sure you delete them all before running `terraform apply` again.\\nWhy are my GCP free credits going so fast? MAGE .tf files - Terraform Destroy not destroying all Resources\\nI checked my GCP billing last night & the MAGE Terraform IaC didn't destroy a GCP Resource called Filestore as ‘mage-data-prep- it has been costing £5.01 of my free credits each day  I now have £151 left - Alexey has assured me that This amount WILL BE SUFFICIENT funds to finish the course. Note to anyone who had issues deploying the MAGE terraform code: check your billing account to see what you're being charged for (main menu - billing) (even if it's your free credits) and run a search for 'mage-data-prep' in the top bar just to be sure that your resources have been destroyed - if any come up delete them.\",\n",
       "  'section': 'Module 2: Workflow Orchestration',\n",
       "  'question': 'GCP - 2.2.7d Part 2 - Getting error when you run terraform apply',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 174},\n",
       " {'text': \"You don't need it. You're accepted. You can also just start learning and submitting homework without registering. It is not checked against any registered list. Registration is just to gauge interest before the start date.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - I have registered for the Data Engineering Bootcamp. When can I expect to receive the confirmation email?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 3},\n",
       " {'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - When will the course start?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 0},\n",
       " {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Can I follow the course after it finishes?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 7},\n",
       " {'text': \"No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Certificate - Can I follow the course in a self-paced mode and get a certificate?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 11},\n",
       " {'text': 'After you create a GitHub account, you should clone the course repo to your local machine using the process outlined in this video: Git for Everybody: How to Clone a Repository from GitHub\\nHaving this local repository on your computer will make it easy for you to access the instructors’ code and make pull requests (if you want to add your own notes or make changes to the course content).\\nYou will probably also create your own repositories that host your notes, versions of your file, to do this. Here is a great tutorial that shows you how to do this: https://www.atlassian.com/git/tutorials/setting-up-a-repository\\nRemember to ignore large database, .csv, and .gz files, and other files that should not be saved to a repository. Use .gitignore for this: https://www.atlassian.com/git/tutorials/saving-changes/gitignore NEVER store passwords or keys in a git repo (even if that repo is set to private).\\nThis is also a great resource: https://dangitgit.com/',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'How do I use Git / GitHub for this course?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 41}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9768c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dedup(seq):\n",
    "    seen = set()\n",
    "    result = []\n",
    "    for el in seq:\n",
    "        _id = el['_id']\n",
    "        if _id in seen:\n",
    "            continue\n",
    "        seen.add(_id)\n",
    "        result.append(el)\n",
    "    return result\n",
    "\n",
    "search_results = dedup(search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2563cfb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 2. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "how do I join the course?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "how to join the course\n",
      "enrollment process\n",
      "course registration\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "section: General course-related questions\n",
      "question: Course - Can I still join the course after the start date?\n",
      "answer: Yes, even if you don't register, you're still eligible to submit the homeworks.\n",
      "Be aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - When will the course start?\n",
      "answer: The purpose of this document is to capture frequently asked technical questions\n",
      "The exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\n",
      "Subscribe to course public Google Calendar (it works from Desktop only).\n",
      "Register before the course starts using this link.\n",
      "Join the course Telegram channel with announcements.\n",
      "Don’t forget to register in DataTalks.Club's Slack and join the channel.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - Can I follow the course after it finishes?\n",
      "answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\n",
      "You can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Certificate - Can I follow the course in a self-paced mode and get a certificate?\n",
      "answer: No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\n",
      "\n",
      "section: General course-related questions\n",
      "question: How do I use Git / GitHub for this course?\n",
      "answer: After you create a GitHub account, you should clone the course repo to your local machine using the process outlined in this video: Git for Everybody: How to Clone a Repository from GitHub\n",
      "Having this local repository on your computer will make it easy for you to access the instructors’ code and make pull requests (if you want to add your own notes or make changes to the course content).\n",
      "You will probably also create your own repositories that host your notes, versions of your file, to do this. Here is a great tutorial that shows you how to do this: https://www.atlassian.com/git/tutorials/setting-up-a-repository\n",
      "Remember to ignore large database, .csv, and .gz files, and other files that should not be saved to a repository. Use .gitignore for this: https://www.atlassian.com/git/tutorials/saving-changes/gitignore NEVER store passwords or keys in a git repo (even if that repo is set to private).\n",
      "This is also a great resource: https://dangitgit.com/\n",
      "\n",
      "section: Module 5: pyspark\n",
      "question: lsRuntimeError: Java gateway process exited before sending its port number\n",
      "answer: After installing all including pyspark (and it is successfully imported), but then running this script on the jupyter notebook\n",
      "import pyspark\n",
      "from pyspark.sql import SparkSession\n",
      "spark = SparkSession.builder \\\n",
      ".master(\"local[*]\") \\\n",
      ".appName('test') \\\n",
      ".getOrCreate()\n",
      "df = spark.read \\\n",
      ".option(\"header\", \"true\") \\\n",
      ".csv('taxi+_zone_lookup.csv')\n",
      "df.show()\n",
      "it gives the error:\n",
      "RuntimeError: Java gateway process exited before sending its port number\n",
      "✅The solution (for me) was:\n",
      "pip install findspark on the command line and then\n",
      "Add\n",
      "import findspark\n",
      "findspark.init()\n",
      "to the top of the script.\n",
      "Another possible solution is:\n",
      "Check that pyspark is pointing to the correct location.\n",
      "Run pyspark.__file__. It should be list /home/<your user name>/spark/spark-3.0.3-bin-hadoop3.2/python/pyspark/__init__.py if you followed the videos.\n",
      "If it is pointing to your python site-packages remove the pyspark directory there and check that you have added the correct exports to you .bashrc file and that there are not any other exports which might supersede the ones provided in the course content.\n",
      "To add to the solution above, if the errors persist in regards to setting the correct path for spark,  an alternative solution for permanent path setting solve the error is  to set environment variables on system and user environment variables following this tutorial: Install Apache PySpark on Windows PC | Apache Spark Installation Guide\n",
      "Once everything is installed, skip to 7:14 to set up environment variables. This allows for the environment variables to be set permanently.\n",
      "\n",
      "section: Module 2: Workflow Orchestration\n",
      "question: Process to download the VSC using Pandas is killed right away\n",
      "answer: pd.read_csv\n",
      "df_iter = pd.read_csv(dataset_url, iterator=True, chunksize=100000)\n",
      "The data needs to be appended to the parquet file using the fastparquet engine\n",
      "df.to_parquet(path, compression=\"gzip\", engine='fastparquet', append=True)\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Docker-Compose - Errors pertaining to docker-compose.yml and pgadmin setup\n",
      "answer: For everyone who's having problem with Docker compose, getting the data in postgres and similar issues, please take care of the following:\n",
      "create a new volume on docker (either using the command line or docker desktop app)\n",
      "make the following changes to your docker-compose.yml file (see attachment)\n",
      "set low_memory=false when importing the csv file (df = pd.read_csv('yellow_tripdata_2021-01.csv', nrows=1000, low_memory=False))\n",
      "use the below function (in the upload-data.ipynb) for better tracking of your ingestion process (see attachment)\n",
      "Order of execution:\n",
      "(1) open terminal in 2_docker_sql folder and run docker compose up\n",
      "(2) ensure no other containers are running except the one you just executed (pgadmin and pgdatabase)\n",
      "(3) open jupyter notebook and begin the data ingestion\n",
      "(4) open pgadmin and set up a server (make sure you use the same configurations as your docker-compose.yml file like the same name (pgdatabase), port, databasename (ny_taxi) etc.\n",
      "\n",
      "section: Module 2: Workflow Orchestration\n",
      "question: GCP - 2.2.7d Part 2 - Getting error when you run terraform apply\n",
      "answer: If you get the following error\n",
      "You have to edit variables.tf on the gcp folder, set your project-id and region and zones properly. Then, run terraform apply again.\n",
      "You can find correct regions/zones here: https://cloud.google.com/compute/docs/regions-zones\n",
      "Deploying MAGE to GCP  with Terraform via the VM (2.2.7)\n",
      "FYI - It can take up to 20 minutes to deploy the MAGE Terraform files if you are using a GCP Virtual Machine. It is normal, so don’t interrupt the process or think it’s taking too long. If you have, make sure you run a terraform destroy before trying again as you will have likely partially created resources which will cause errors next time you run `terraform apply`.\n",
      "`terraform destroy` may not completely delete partial resources - go to Google Cloud Console and use the search bar at the top to search for the ‘app.name’ you declared in your variables.tf file; this will list all resources with that name - make sure you delete them all before running `terraform apply` again.\n",
      "Why are my GCP free credits going so fast? MAGE .tf files - Terraform Destroy not destroying all Resources\n",
      "I checked my GCP billing last night & the MAGE Terraform IaC didn't destroy a GCP Resource called Filestore as ‘mage-data-prep- it has been costing £5.01 of my free credits each day  I now have £151 left - Alexey has assured me that This amount WILL BE SUFFICIENT funds to finish the course. Note to anyone who had issues deploying the MAGE terraform code: check your billing account to see what you're being charged for (main menu - billing) (even if it's your free credits) and run a search for 'mage-data-prep' in the top bar just to be sure that your resources have been destroyed - if any come up delete them.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - I have registered for the Data Engineering Bootcamp. When can I expect to receive the confirmation email?\n",
      "answer: You don't need it. You're accepted. You can also just start learning and submitting homework without registering. It is not checked against any registered list. Registration is just to gauge interest before the start date.\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"To provide accurate information on how to join the course, I need to look for relevant details in the FAQ database.\", \"keywords\": [\"how to join the course\", \"enrollment process\", \"course registration\"]}\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"ANSWER_CONTEXT\",\n",
      "  \"answer\": \"To join the course, you need to register before the course starts, which is on January 15, 2024, at 17:00. You can register using the provided link. You don't need a confirmation email, as you're accepted once you register, and you're also eligible to start learning and submitting homework immediately, even without formal registration. Additionally, make sure to join the course's public Google Calendar and the announcements Telegram channel for updates.\",\n",
      "  \"source\": \"CONTEXT\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# question = \"how do I join the course?\"\n",
    "\n",
    "# search_queries = []\n",
    "# search_results = []\n",
    "# previous_actions = []\n",
    "\n",
    "context = build_context(search_results)\n",
    "\n",
    "prompt = prompt_template.format(\n",
    "    question=question,\n",
    "    context=context,\n",
    "    search_queries=\"\\n\".join(search_queries),\n",
    "    previous_actions='\\n'.join([json.dumps(a) for a in previous_actions]),\n",
    "    max_iterations=3,\n",
    "    iteration_number=2\n",
    ")\n",
    "print(prompt)\n",
    "\n",
    "answer_json = llm(prompt)\n",
    "answer = json.loads(answer_json)\n",
    "print(json.dumps(answer, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4938b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION #0...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 0. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "what do I need to do to be successful at module 1?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"SEARCH\",\n",
      "  \"reasoning\": \"To provide a comprehensive answer, I need to gather information on best practices and strategies for succeeding in Module 1, including study tips, course requirements, and resources available.\",\n",
      "  \"keywords\": [\n",
      "    \"successful strategies for Module 1\",\n",
      "    \"how to do well in Module 1\",\n",
      "    \"Module 1 study tips\",\n",
      "    \"Module 1 requirements\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "ITERATION #1...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 1. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "what do I need to do to be successful at module 1?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "Module 1 requirements\n",
      "Module 1 study tips\n",
      "successful strategies for Module 1\n",
      "how to do well in Module 1\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "section: Module 5: pyspark\n",
      "question: Module Not Found Error in Jupyter Notebook .\n",
      "answer: Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\n",
      "The solution which worked for me(use following in jupyter notebook) :\n",
      "!pip install findspark\n",
      "import findspark\n",
      "findspark.init()\n",
      "Thereafter , import pyspark and create spark contex<<t as usual\n",
      "None of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\n",
      "Filter based on conditions based on multiple columns\n",
      "from pyspark.sql.functions import col\n",
      "new_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\n",
      "Krishna Anand\n",
      "\n",
      "section: Module 5: pyspark\n",
      "question: Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\n",
      "answer: You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\n",
      "` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\n",
      "export PYTHONPATH=”${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}”\n",
      "Make sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\n",
      "For instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\n",
      "Then the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\n",
      "Additionally, you can check for the version of ‘py4j’ of the spark you’re using from here and update as mentioned above.\n",
      "~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Postgres - ModuleNotFoundError: No module named 'psycopg2'\n",
      "answer: Issue:\n",
      "e…\n",
      "Solution:\n",
      "pip install psycopg2-binary\n",
      "If you already have it, you might need to update it:\n",
      "pip install psycopg2-binary --upgrade\n",
      "Other methods, if the above fails:\n",
      "if you are getting the “ ModuleNotFoundError: No module named 'psycopg2' “ error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\n",
      "First uninstall the psycopg package\n",
      "Then update conda or pip\n",
      "Then install psycopg again using pip.\n",
      "if you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\n",
      "\n",
      "section: Module 4: analytics engineering with dbt\n",
      "question: DBT - Error: No module named 'pytz' while setting up dbt with docker\n",
      "answer: Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\n",
      "Solution:\n",
      "Add `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLALchemy - TypeError 'module' object is not callable\n",
      "answer: create_engine('postgresql://root:root@localhost:5432/ny_taxi')  I get the error \"TypeError: 'module' object is not callable\"\n",
      "Solution:\n",
      "conn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\n",
      "engine = create_engine(conn_string)\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLAlchemy - ModuleNotFoundError: No module named 'psycopg2'.\n",
      "answer: Error raised during the jupyter notebook’s cell execution:\n",
      "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi').\n",
      "Solution: Need to install Python module “psycopg2”. Can be installed by Conda or pip.\n",
      "\n",
      "section: Module 6: streaming with kafka\n",
      "question: Module “kafka” not found when trying to run producer.py\n",
      "answer: Solution from Alexey: create a virtual environment and run requirements.txt and the python files in that environment.\n",
      "To create a virtual env and install packages (run only once)\n",
      "python -m venv env\n",
      "source env/bin/activate\n",
      "pip install -r ../requirements.txt\n",
      "To activate it (you'll need to run it every time you need the virtual env):\n",
      "source env/bin/activate\n",
      "To deactivate it:\n",
      "deactivate\n",
      "This works on MacOS, Linux and Windows - but for Windows the path is slightly different (it's env/Scripts/activate)\n",
      "Also the virtual environment should be created only to run the python file. Docker images should first all be up and running.\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"To provide a comprehensive answer, I need to gather information on best practices and strategies for succeeding in Module 1, including study tips, course requirements, and resources available.\", \"keywords\": [\"successful strategies for Module 1\", \"how to do well in Module 1\", \"Module 1 study tips\", \"Module 1 requirements\"]}\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"SEARCH\",\n",
      "  \"reasoning\": \"I need to gather more detailed insights specifically focused on the requirements and study tips for Module 1, as these are critical for the student's success in that module.\",\n",
      "  \"keywords\": [\n",
      "    \"Module 1 requirements\",\n",
      "    \"Module 1 study tips\",\n",
      "    \"how to excel in Module 1\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "ITERATION #2...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 2. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "what do I need to do to be successful at module 1?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "how to excel in Module 1\n",
      "successful strategies for Module 1\n",
      "how to do well in Module 1\n",
      "Module 1 requirements\n",
      "Module 1 study tips\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "section: Module 5: pyspark\n",
      "question: Module Not Found Error in Jupyter Notebook .\n",
      "answer: Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\n",
      "The solution which worked for me(use following in jupyter notebook) :\n",
      "!pip install findspark\n",
      "import findspark\n",
      "findspark.init()\n",
      "Thereafter , import pyspark and create spark contex<<t as usual\n",
      "None of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\n",
      "Filter based on conditions based on multiple columns\n",
      "from pyspark.sql.functions import col\n",
      "new_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\n",
      "Krishna Anand\n",
      "\n",
      "section: Module 5: pyspark\n",
      "question: Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\n",
      "answer: You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\n",
      "` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\n",
      "export PYTHONPATH=”${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}”\n",
      "Make sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\n",
      "For instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\n",
      "Then the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\n",
      "Additionally, you can check for the version of ‘py4j’ of the spark you’re using from here and update as mentioned above.\n",
      "~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Postgres - ModuleNotFoundError: No module named 'psycopg2'\n",
      "answer: Issue:\n",
      "e…\n",
      "Solution:\n",
      "pip install psycopg2-binary\n",
      "If you already have it, you might need to update it:\n",
      "pip install psycopg2-binary --upgrade\n",
      "Other methods, if the above fails:\n",
      "if you are getting the “ ModuleNotFoundError: No module named 'psycopg2' “ error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\n",
      "First uninstall the psycopg package\n",
      "Then update conda or pip\n",
      "Then install psycopg again using pip.\n",
      "if you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\n",
      "\n",
      "section: Module 4: analytics engineering with dbt\n",
      "question: DBT - Error: No module named 'pytz' while setting up dbt with docker\n",
      "answer: Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\n",
      "Solution:\n",
      "Add `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLALchemy - TypeError 'module' object is not callable\n",
      "answer: create_engine('postgresql://root:root@localhost:5432/ny_taxi')  I get the error \"TypeError: 'module' object is not callable\"\n",
      "Solution:\n",
      "conn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\n",
      "engine = create_engine(conn_string)\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLAlchemy - ModuleNotFoundError: No module named 'psycopg2'.\n",
      "answer: Error raised during the jupyter notebook’s cell execution:\n",
      "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi').\n",
      "Solution: Need to install Python module “psycopg2”. Can be installed by Conda or pip.\n",
      "\n",
      "section: Module 6: streaming with kafka\n",
      "question: Module “kafka” not found when trying to run producer.py\n",
      "answer: Solution from Alexey: create a virtual environment and run requirements.txt and the python files in that environment.\n",
      "To create a virtual env and install packages (run only once)\n",
      "python -m venv env\n",
      "source env/bin/activate\n",
      "pip install -r ../requirements.txt\n",
      "To activate it (you'll need to run it every time you need the virtual env):\n",
      "source env/bin/activate\n",
      "To deactivate it:\n",
      "deactivate\n",
      "This works on MacOS, Linux and Windows - but for Windows the path is slightly different (it's env/Scripts/activate)\n",
      "Also the virtual environment should be created only to run the python file. Docker images should first all be up and running.\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"To provide a comprehensive answer, I need to gather information on best practices and strategies for succeeding in Module 1, including study tips, course requirements, and resources available.\", \"keywords\": [\"successful strategies for Module 1\", \"how to do well in Module 1\", \"Module 1 study tips\", \"Module 1 requirements\"]}\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"I need to gather more detailed insights specifically focused on the requirements and study tips for Module 1, as these are critical for the student's success in that module.\", \"keywords\": [\"Module 1 requirements\", \"Module 1 study tips\", \"how to excel in Module 1\"]}\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"ANSWER\",\n",
      "  \"answer\": \"To be successful in Module 1, which focuses on Docker and Terraform, you should consider the following strategies: \\n1. **Understand the basics of Docker**: Familiarize yourself with containerization concepts, how to create and manage containers, and using Docker images effectively. \\n2. **Master Terraform**: Learn about infrastructure as code principles, how to write Terraform configurations, and managing state files. \\n3. **Hands-on Practice**: Work on practical projects that involve setting up Docker containers and deploying applications with Terraform. \\n4. **Engage with Resources**: Use official documentation, tutorials, and community forums to enhance your understanding. \\n5. **Collaborate and Discuss**: Join study groups or forums to discuss challenges and solutions with peers. \\n6. **Stay Organized**: Keep your notes and resources well-organized for easy revision and reference.\\nSuccess in this module will also require you to perform assignments and participate actively in discussions, as practical engagement is key to grasping the concepts well.\",\n",
      "  \"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "question = \"what do I need to do to be successful at module 1?\"\n",
    "\n",
    "search_queries = []\n",
    "search_results = []\n",
    "previous_actions = []\n",
    "\n",
    "\n",
    "iteration = 0\n",
    "\n",
    "while True:\n",
    "    print(f'ITERATION #{iteration}...')\n",
    "\n",
    "    context = build_context(search_results)\n",
    "    prompt = prompt_template.format(\n",
    "        question=question,\n",
    "        context=context,\n",
    "        search_queries=\"\\n\".join(search_queries),\n",
    "        previous_actions='\\n'.join([json.dumps(a) for a in previous_actions]),\n",
    "        max_iterations=3,\n",
    "        iteration_number=iteration\n",
    "    )\n",
    "\n",
    "    print(prompt)\n",
    "\n",
    "    answer_json = llm(prompt)\n",
    "    answer = json.loads(answer_json)\n",
    "    print(json.dumps(answer, indent=2))\n",
    "\n",
    "    previous_actions.append(answer)\n",
    "\n",
    "    action = answer['action']\n",
    "    if action != 'SEARCH':\n",
    "        break\n",
    "\n",
    "    keywords = answer['keywords']\n",
    "    search_queries = list(set(search_queries) | set(keywords))\n",
    "    \n",
    "    for k in keywords:\n",
    "        res = search(k)\n",
    "        search_results.extend(res)\n",
    "\n",
    "    search_results = dedup(search_results)\n",
    "    \n",
    "    iteration = iteration + 1\n",
    "    if iteration >= 4:\n",
    "        break\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf4c2755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agentic_search(question):\n",
    "    search_queries = []\n",
    "    search_results = []\n",
    "    previous_actions = []\n",
    "\n",
    "    iteration = 0\n",
    "    \n",
    "    while True:\n",
    "        print(f'ITERATION #{iteration}...')\n",
    "    \n",
    "        context = build_context(search_results)\n",
    "        prompt = prompt_template.format(\n",
    "            question=question,\n",
    "            context=context,\n",
    "            search_queries=\"\\n\".join(search_queries),\n",
    "            previous_actions='\\n'.join([json.dumps(a) for a in previous_actions]),\n",
    "            max_iterations=3,\n",
    "            iteration_number=iteration\n",
    "        )\n",
    "    \n",
    "        print(prompt)\n",
    "    \n",
    "        answer_json = llm(prompt)\n",
    "        answer = json.loads(answer_json)\n",
    "        print(json.dumps(answer, indent=2))\n",
    "\n",
    "        previous_actions.append(answer)\n",
    "    \n",
    "        action = answer['action']\n",
    "        if action != 'SEARCH':\n",
    "            break\n",
    "    \n",
    "        keywords = answer['keywords']\n",
    "        search_queries = list(set(search_queries) | set(keywords))\n",
    "\n",
    "        for k in keywords:\n",
    "            res = search(k)\n",
    "            search_results.extend(res)\n",
    "    \n",
    "        search_results = dedup(search_results)\n",
    "        \n",
    "        iteration = iteration + 1\n",
    "        if iteration >= 4:\n",
    "            break\n",
    "    \n",
    "        print()\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "afbe4807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION #0...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 0. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "how do I prepare for the course?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"SEARCH\",\n",
      "  \"reasoning\": \"The question pertains to course preparation, which involves understanding resources, study strategies, and possibly key topics of focus. By searching for documents related to course preparation, I can gather relevant information that will help answer the student's query more thoroughly.\",\n",
      "  \"keywords\": [\n",
      "    \"course preparation\",\n",
      "    \"how to prepare for classes\",\n",
      "    \"study tips for the course\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "ITERATION #1...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 1. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "how do I prepare for the course?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "how to prepare for classes\n",
      "course preparation\n",
      "study tips for the course\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "section: General course-related questions\n",
      "question: Course - When will the course start?\n",
      "answer: The purpose of this document is to capture frequently asked technical questions\n",
      "The exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\n",
      "Subscribe to course public Google Calendar (it works from Desktop only).\n",
      "Register before the course starts using this link.\n",
      "Join the course Telegram channel with announcements.\n",
      "Don’t forget to register in DataTalks.Club's Slack and join the channel.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - Can I follow the course after it finishes?\n",
      "answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\n",
      "You can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Certificate - Can I follow the course in a self-paced mode and get a certificate?\n",
      "answer: No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Is it possible to use tool “X” instead of the one tool you use in the course?\n",
      "answer: Yes, this applies if you want to use Airflow or Prefect instead of Mage, AWS or Snowflake instead of GCP products or Tableau instead of Metabase or Google data studio.\n",
      "The course covers 2 alternative data stacks, one using GCP and one using local installation of everything. You can use one of them or use your tool of choice.\n",
      "Should you consider it instead of the one tool you use? That we can’t support you if you choose to use a different stack, also you would need to explain the different choices of tool for the peer review of your capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: How do I use Git / GitHub for this course?\n",
      "answer: After you create a GitHub account, you should clone the course repo to your local machine using the process outlined in this video: Git for Everybody: How to Clone a Repository from GitHub\n",
      "Having this local repository on your computer will make it easy for you to access the instructors’ code and make pull requests (if you want to add your own notes or make changes to the course content).\n",
      "You will probably also create your own repositories that host your notes, versions of your file, to do this. Here is a great tutorial that shows you how to do this: https://www.atlassian.com/git/tutorials/setting-up-a-repository\n",
      "Remember to ignore large database, .csv, and .gz files, and other files that should not be saved to a repository. Use .gitignore for this: https://www.atlassian.com/git/tutorials/saving-changes/gitignore NEVER store passwords or keys in a git repo (even if that repo is set to private).\n",
      "This is also a great resource: https://dangitgit.com/\n",
      "\n",
      "section: Module 5: pyspark\n",
      "question: Spark Cloud Storage connector\n",
      "answer: Link to Slack Thread : has anyone figured out how to read from GCP data lake instead of downloading all the taxi data again?\n",
      "There’s a few extra steps to go into reading from GCS with PySpark\n",
      "1.)  IMPORTANT: Download the Cloud Storage connector for Hadoop here: https://cloud.google.com/dataproc/docs/concepts/connectors/cloud-storage#clusters\n",
      "As the name implies, this .jar file is what essentially connects PySpark with your GCS\n",
      "2.) Move the .jar file to your Spark file directory. I installed Spark using homebrew on my MacOS machine and I had to create a /jars directory under \"/opt/homebrew/Cellar/apache-spark/3.2.1/ (where my spark dir is located)\n",
      "3.) In your Python script, there are a few extra classes you’ll have to import:\n",
      "import pyspark\n",
      "from pyspark.sql import SparkSession\n",
      "from pyspark.conf import SparkConf\n",
      "from pyspark.context import SparkContext\n",
      "4.) You must set up your configurations before building your SparkSession. Here’s my code snippet:\n",
      "conf = SparkConf() \\\n",
      ".setMaster('local[*]') \\\n",
      ".setAppName('test') \\\n",
      ".set(\"spark.jars\", \"/opt/homebrew/Cellar/apache-spark/3.2.1/jars/gcs-connector-hadoop3-latest.jar\") \\\n",
      ".set(\"spark.hadoop.google.cloud.auth.service.account.enable\", \"true\") \\\n",
      ".set(\"spark.hadoop.google.cloud.auth.service.account.json.keyfile\", \"path/to/google_credentials.json\")\n",
      "sc = SparkContext(conf=conf)\n",
      "sc._jsc.hadoopConfiguration().set(\"fs.AbstractFileSystem.gs.impl\",  \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\")\n",
      "sc._jsc.hadoopConfiguration().set(\"fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\")\n",
      "sc._jsc.hadoopConfiguration().set(\"fs.gs.auth.service.account.json.keyfile\", \"path/to/google_credentials.json\")\n",
      "sc._jsc.hadoopConfiguration().set(\"fs.gs.auth.service.account.enable\", \"true\")\n",
      "5.) Once you run that, build your SparkSession with the new parameters we’d just instantiated in the previous step:\n",
      "spark = SparkSession.builder \\\n",
      ".config(conf=sc.getConf()) \\\n",
      ".getOrCreate()\n",
      "6.) Finally, you’re able to read your files straight from GCS!\n",
      "df_green = spark.read.parquet(\"gs://{BUCKET}/green/202*/\")\n",
      "\n",
      "section: Module 6: streaming with kafka\n",
      "question: Java Kafka: Tests are not picked up in VSCode\n",
      "answer: Situation: in VS Code, usually there will be a triangle icon next to each test. I couldn’t see it at first and had to do some fixes.\n",
      "Solution:\n",
      "(Source)\n",
      "VS Code\n",
      "→ Explorer (first icon on the left navigation bar)\n",
      "→ JAVA PROJECTS (bottom collapsable)\n",
      "→  icon next in the rightmost position to JAVA PROJECTS\n",
      "→  clean Workspace\n",
      "→ Confirm by clicking Reload and Delete\n",
      "Now you will be able to see the triangle icon next to each test like what you normally see in python tests.\n",
      "E.g.:\n",
      "You can also add classes and packages in this window instead of creating files in the project directory\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"The question pertains to course preparation, which involves understanding resources, study strategies, and possibly key topics of focus. By searching for documents related to course preparation, I can gather relevant information that will help answer the student's query more thoroughly.\", \"keywords\": [\"course preparation\", \"how to prepare for classes\", \"study tips for the course\"]}\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"SEARCH\",\n",
      "  \"reasoning\": \"To provide a more comprehensive answer regarding course preparation, I will look for any specific tips, strategies, or resources mentioned in the FAQ that could aid students in getting ready for the course.\",\n",
      "  \"keywords\": [\n",
      "    \"course study tips\",\n",
      "    \"course preparation strategies\",\n",
      "    \"how to succeed in the course\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "ITERATION #2...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 2. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "how do I prepare for the course?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "how to prepare for classes\n",
      "how to succeed in the course\n",
      "course study tips\n",
      "course preparation\n",
      "course preparation strategies\n",
      "study tips for the course\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "section: General course-related questions\n",
      "question: Course - When will the course start?\n",
      "answer: The purpose of this document is to capture frequently asked technical questions\n",
      "The exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\n",
      "Subscribe to course public Google Calendar (it works from Desktop only).\n",
      "Register before the course starts using this link.\n",
      "Join the course Telegram channel with announcements.\n",
      "Don’t forget to register in DataTalks.Club's Slack and join the channel.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - Can I follow the course after it finishes?\n",
      "answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\n",
      "You can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Certificate - Can I follow the course in a self-paced mode and get a certificate?\n",
      "answer: No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Is it possible to use tool “X” instead of the one tool you use in the course?\n",
      "answer: Yes, this applies if you want to use Airflow or Prefect instead of Mage, AWS or Snowflake instead of GCP products or Tableau instead of Metabase or Google data studio.\n",
      "The course covers 2 alternative data stacks, one using GCP and one using local installation of everything. You can use one of them or use your tool of choice.\n",
      "Should you consider it instead of the one tool you use? That we can’t support you if you choose to use a different stack, also you would need to explain the different choices of tool for the peer review of your capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: How do I use Git / GitHub for this course?\n",
      "answer: After you create a GitHub account, you should clone the course repo to your local machine using the process outlined in this video: Git for Everybody: How to Clone a Repository from GitHub\n",
      "Having this local repository on your computer will make it easy for you to access the instructors’ code and make pull requests (if you want to add your own notes or make changes to the course content).\n",
      "You will probably also create your own repositories that host your notes, versions of your file, to do this. Here is a great tutorial that shows you how to do this: https://www.atlassian.com/git/tutorials/setting-up-a-repository\n",
      "Remember to ignore large database, .csv, and .gz files, and other files that should not be saved to a repository. Use .gitignore for this: https://www.atlassian.com/git/tutorials/saving-changes/gitignore NEVER store passwords or keys in a git repo (even if that repo is set to private).\n",
      "This is also a great resource: https://dangitgit.com/\n",
      "\n",
      "section: Module 5: pyspark\n",
      "question: Spark Cloud Storage connector\n",
      "answer: Link to Slack Thread : has anyone figured out how to read from GCP data lake instead of downloading all the taxi data again?\n",
      "There’s a few extra steps to go into reading from GCS with PySpark\n",
      "1.)  IMPORTANT: Download the Cloud Storage connector for Hadoop here: https://cloud.google.com/dataproc/docs/concepts/connectors/cloud-storage#clusters\n",
      "As the name implies, this .jar file is what essentially connects PySpark with your GCS\n",
      "2.) Move the .jar file to your Spark file directory. I installed Spark using homebrew on my MacOS machine and I had to create a /jars directory under \"/opt/homebrew/Cellar/apache-spark/3.2.1/ (where my spark dir is located)\n",
      "3.) In your Python script, there are a few extra classes you’ll have to import:\n",
      "import pyspark\n",
      "from pyspark.sql import SparkSession\n",
      "from pyspark.conf import SparkConf\n",
      "from pyspark.context import SparkContext\n",
      "4.) You must set up your configurations before building your SparkSession. Here’s my code snippet:\n",
      "conf = SparkConf() \\\n",
      ".setMaster('local[*]') \\\n",
      ".setAppName('test') \\\n",
      ".set(\"spark.jars\", \"/opt/homebrew/Cellar/apache-spark/3.2.1/jars/gcs-connector-hadoop3-latest.jar\") \\\n",
      ".set(\"spark.hadoop.google.cloud.auth.service.account.enable\", \"true\") \\\n",
      ".set(\"spark.hadoop.google.cloud.auth.service.account.json.keyfile\", \"path/to/google_credentials.json\")\n",
      "sc = SparkContext(conf=conf)\n",
      "sc._jsc.hadoopConfiguration().set(\"fs.AbstractFileSystem.gs.impl\",  \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\")\n",
      "sc._jsc.hadoopConfiguration().set(\"fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\")\n",
      "sc._jsc.hadoopConfiguration().set(\"fs.gs.auth.service.account.json.keyfile\", \"path/to/google_credentials.json\")\n",
      "sc._jsc.hadoopConfiguration().set(\"fs.gs.auth.service.account.enable\", \"true\")\n",
      "5.) Once you run that, build your SparkSession with the new parameters we’d just instantiated in the previous step:\n",
      "spark = SparkSession.builder \\\n",
      ".config(conf=sc.getConf()) \\\n",
      ".getOrCreate()\n",
      "6.) Finally, you’re able to read your files straight from GCS!\n",
      "df_green = spark.read.parquet(\"gs://{BUCKET}/green/202*/\")\n",
      "\n",
      "section: Module 6: streaming with kafka\n",
      "question: Java Kafka: Tests are not picked up in VSCode\n",
      "answer: Situation: in VS Code, usually there will be a triangle icon next to each test. I couldn’t see it at first and had to do some fixes.\n",
      "Solution:\n",
      "(Source)\n",
      "VS Code\n",
      "→ Explorer (first icon on the left navigation bar)\n",
      "→ JAVA PROJECTS (bottom collapsable)\n",
      "→  icon next in the rightmost position to JAVA PROJECTS\n",
      "→  clean Workspace\n",
      "→ Confirm by clicking Reload and Delete\n",
      "Now you will be able to see the triangle icon next to each test like what you normally see in python tests.\n",
      "E.g.:\n",
      "You can also add classes and packages in this window instead of creating files in the project directory\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"The question pertains to course preparation, which involves understanding resources, study strategies, and possibly key topics of focus. By searching for documents related to course preparation, I can gather relevant information that will help answer the student's query more thoroughly.\", \"keywords\": [\"course preparation\", \"how to prepare for classes\", \"study tips for the course\"]}\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"To provide a more comprehensive answer regarding course preparation, I will look for any specific tips, strategies, or resources mentioned in the FAQ that could aid students in getting ready for the course.\", \"keywords\": [\"course study tips\", \"course preparation strategies\", \"how to succeed in the course\"]}\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"ANSWER\",\n",
      "  \"answer\": \"To prepare for the course, make sure you register before it starts on January 15, 2024, and join the course's communication channels like the Google Calendar and Telegram channel for updates. Familiarize yourself with the course materials, which will be accessible after the course concludes for at-your-own-pace study. If you're using GitHub for the course, ensure you understand how to clone repositories and manage your files effectively, as this will aid your collaboration and learning. Additionally, reviewing any tutorials or resources related to the tools you will use in the course can be beneficial. Staying organized and proactive in your learning will help you succeed.\",\n",
      "  \"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'action': 'ANSWER',\n",
       " 'answer': \"To prepare for the course, make sure you register before it starts on January 15, 2024, and join the course's communication channels like the Google Calendar and Telegram channel for updates. Familiarize yourself with the course materials, which will be accessible after the course concludes for at-your-own-pace study. If you're using GitHub for the course, ensure you understand how to clone repositories and manage your files effectively, as this will aid your collaboration and learning. Additionally, reviewing any tutorials or resources related to the tools you will use in the course can be beneficial. Staying organized and proactive in your learning will help you succeed.\",\n",
       " 'source': 'OWN_KNOWLEDGE'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agentic_search('how do I prepare for the course?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58f306b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5,\n",
    "        output_ids=True\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7db04cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"search\",\n",
    "    \"description\": \"Search the FAQ database\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Search query text to look up in the course FAQ.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"query\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f30bc5ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ResponseFunctionToolCall(arguments='{\"query\":\"how to do well in module 1\"}', call_id='call_uEKLwQzA41055j0tdsNe2ZQK', name='search', type='function_call', id='fc_68782e44c0dc819b8d30a46079eb4cee06e69ea4807507f0', status='completed')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"How do I do well in module 1?\"\n",
    "\n",
    "developer_prompt = \"\"\"\n",
    "You're a course teaching assistant. \n",
    "You're given a question from a course student and your task is to answer it.\n",
    "\"\"\".strip()\n",
    "\n",
    "tools = [search_tool]\n",
    "\n",
    "chat_messages = [\n",
    "    {\"role\": \"developer\", \"content\": developer_prompt},\n",
    "    {\"role\": \"user\", \"content\": question}\n",
    "]\n",
    "\n",
    "response = client.responses.create(\n",
    "    model='gpt-4o-mini',\n",
    "    input=chat_messages,\n",
    "    tools=tools\n",
    ")\n",
    "response.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad38c462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'how to do well in module 1'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calls = response.output\n",
    "call = calls[0]\n",
    "call\n",
    "\n",
    "call_id = call.call_id\n",
    "call_id\n",
    "\n",
    "f_name = call.name\n",
    "f_name\n",
    "\n",
    "arguments = json.loads(call.arguments)\n",
    "arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3a74eb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = globals()[f_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5ab059c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = f(**arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4cb1d404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"text\": \"Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\\nThe solution which worked for me(use following in jupyter notebook) :\\n!pip install findspark\\nimport findspark\\nfindspark.init()\\nThereafter , import pyspark and create spark contex<<t as usual\\nNone of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\\nFilter based on conditions based on multiple columns\\nfrom pyspark.sql.functions import col\\nnew_final.filter((new_final.a_zone==\\\"Murray Hill\\\") & (new_final.b_zone==\\\"Midwood\\\")).show()\\nKrishna Anand\",\n",
      "    \"section\": \"Module 5: pyspark\",\n",
      "    \"question\": \"Module Not Found Error in Jupyter Notebook .\",\n",
      "    \"course\": \"data-engineering-zoomcamp\",\n",
      "    \"_id\": 322\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\\n` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\\nexport PYTHONPATH=\\u201d${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}\\u201d\\nMake sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\\nFor instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\\nThen the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\\\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\\\"` appropriately.\\nAdditionally, you can check for the version of \\u2018py4j\\u2019 of the spark you\\u2019re using from here and update as mentioned above.\\n~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\",\n",
      "    \"section\": \"Module 5: pyspark\",\n",
      "    \"question\": \"Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\",\n",
      "    \"course\": \"data-engineering-zoomcamp\",\n",
      "    \"_id\": 323\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\\nSolution:\\nAdd `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\",\n",
      "    \"section\": \"Module 4: analytics engineering with dbt\",\n",
      "    \"question\": \"DBT - Error: No module named 'pytz' while setting up dbt with docker\",\n",
      "    \"course\": \"data-engineering-zoomcamp\",\n",
      "    \"_id\": 299\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"create_engine('postgresql://root:root@localhost:5432/ny_taxi')  I get the error \\\"TypeError: 'module' object is not callable\\\"\\nSolution:\\nconn_string = \\\"postgresql+psycopg://root:root@localhost:5432/ny_taxi\\\"\\nengine = create_engine(conn_string)\",\n",
      "    \"section\": \"Module 1: Docker and Terraform\",\n",
      "    \"question\": \"Python - SQLALchemy - TypeError 'module' object is not callable\",\n",
      "    \"course\": \"data-engineering-zoomcamp\",\n",
      "    \"_id\": 124\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"Error raised during the jupyter notebook\\u2019s cell execution:\\nengine = create_engine('postgresql://root:root@localhost:5432/ny_taxi').\\nSolution: Need to install Python module \\u201cpsycopg2\\u201d. Can be installed by Conda or pip.\",\n",
      "    \"section\": \"Module 1: Docker and Terraform\",\n",
      "    \"question\": \"Python - SQLAlchemy - ModuleNotFoundError: No module named 'psycopg2'.\",\n",
      "    \"course\": \"data-engineering-zoomcamp\",\n",
      "    \"_id\": 125\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "search_results = json.dumps(results, indent=2)\n",
    "print(search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "db2a93cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_messages.append(call)\n",
    "\n",
    "chat_messages.append({\n",
    "    \"type\": \"function_call_output\",\n",
    "    \"call_id\": call.call_id,\n",
    "    \"output\": search_results,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "07305dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.responses.create(\n",
    "    model='gpt-4o-mini',\n",
    "    input=chat_messages,\n",
    "    tools=tools\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "54b01e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To do well in Module 1 of the course, here are some tips and suggestions:\n",
      "\n",
      "1. **Understand the Basics**: Make sure you have a solid grasp of Docker and Terraform concepts, as they are fundamental to this module.\n",
      "\n",
      "2. **Follow Instructions Carefully**: Pay close attention to the setup instructions for Docker and Terraform. Any misconfiguration can lead to errors.\n",
      "\n",
      "3. **Practice Coding**: If you're working with Python and SQLAlchemy, practice writing and executing code examples provided in the module. For instance, ensure you can create engine connections without errors.\n",
      "\n",
      "4. **Troubleshoot Common Errors**: Be proactive in troubleshooting common issues, such as:\n",
      "   - The `ModuleNotFoundError` for `psycopg2` can often be resolved by installing the package using `pip install psycopg2`.\n",
      "   - If you encounter other module-related issues, make sure your environment is set up correctly and all dependencies are installed.\n",
      "\n",
      "5. **Engage with the Community**: Utilize the course forums or discussion boards to ask questions, share knowledge, and get insights from peers or instructors.\n",
      "\n",
      "6. **Complete All Assignments**: Make sure you complete all assignments and exercises as they provide practical experience.\n",
      "\n",
      "7. **Seek Feedback**: If possible, seek feedback on any projects or assignments to improve further.\n",
      "\n",
      "Following these strategies should help you perform well in Module 1! If you have specific challenges, feel free to ask for more tailored assistance.\n"
     ]
    }
   ],
   "source": [
    "r = response.output[0]\n",
    "print(r.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b6160138",
   "metadata": {},
   "outputs": [],
   "source": [
    "developer_prompt = \"\"\"\n",
    "You're a course teaching assistant. \n",
    "You're given a question from a course student and your task is to answer it.\n",
    "If you look up something in FAQ, convert the student question into multiple queries.\n",
    "\"\"\".strip()\n",
    "\n",
    "chat_messages = [\n",
    "    {\"role\": \"developer\", \"content\": developer_prompt},\n",
    "    {\"role\": \"user\", \"content\": question}\n",
    "]\n",
    "\n",
    "response = client.responses.create(\n",
    "    model='gpt-4o-mini',\n",
    "    input=chat_messages,\n",
    "    tools=tools\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7a42c80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_call(tool_call_response):\n",
    "    function_name = tool_call_response.name\n",
    "    arguments = json.loads(tool_call_response.arguments)\n",
    "\n",
    "    f = globals()[function_name]\n",
    "    result = f(**arguments)\n",
    "\n",
    "    return {\n",
    "        \"type\": \"function_call_output\",\n",
    "        \"call_id\": tool_call_response.call_id,\n",
    "        \"output\": json.dumps(result, indent=2),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "214b7ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function_call\n",
      "function_call\n",
      "function_call\n"
     ]
    }
   ],
   "source": [
    "for entry in response.output:\n",
    "    chat_messages.append(entry)\n",
    "    print(entry.type)\n",
    "\n",
    "    if entry.type == 'function_call':      \n",
    "        result = do_call(entry)\n",
    "        chat_messages.append(result)\n",
    "    elif entry.type == 'message':\n",
    "        print(entry.text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "08177c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "message\n",
      "\n",
      "To do well in Module 1 of the course, here are some strategies and tips:\n",
      "\n",
      "1. **Understand the Basics of Docker and Terraform**:\n",
      "   - Make sure you grasp the core concepts of both Docker and Terraform. Review their documentation and understand how they function.\n",
      "\n",
      "2. **Practice regularly**:\n",
      "   - Spend time practicing with Docker and Terraform in a hands-on manner. Set up your own local environments and try to recreate the examples provided in the course.\n",
      "\n",
      "3. **Solve Common Issues**:\n",
      "   - Familiarize yourself with common errors, such as:\n",
      "     - `ModuleNotFoundError: No module named 'psycopg2'`. If you encounter this, ensure you install it using:\n",
      "       ```bash\n",
      "       pip install psycopg2-binary\n",
      "       ```\n",
      "     - If you see an error related to SQLAlchemy, such as `TypeError: 'module' object is not callable`, make sure you are using the correct connection string for creating the engine.\n",
      "\n",
      "4. **Implementation of Projects**:\n",
      "   - Try implementing a small project using Docker and Terraform to solidify your understanding. This could be as simple as deploying a web application.\n",
      "\n",
      "5. **Consult the Community**:\n",
      "   - Engage with your peers or online communities to get support, share knowledge, and find alternative solutions to problems you may encounter.\n",
      "\n",
      "6. **Stay Organized**:\n",
      "   - Keep your files and code organized. Use version control (like Git) to track changes in your projects.\n",
      "\n",
      "7. **Seek Help When Needed**:\n",
      "   - Don’t hesitate to ask for help if you’re stuck. Use forums, your instructors, or study groups.\n",
      "\n",
      "By following these strategies and staying engaged with the course material, you will enhance your chances of succeeding in Module 1.\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model='gpt-4o-mini',\n",
    "    input=chat_messages,\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "for entry in response.output:\n",
    "    chat_messages.append(entry)\n",
    "    print(entry.type)\n",
    "    print()\n",
    "\n",
    "    if entry.type == 'function_call':      \n",
    "        result = do_call(entry)\n",
    "        chat_messages.append(result)\n",
    "    elif entry.type == 'message':\n",
    "        print(entry.content[0].text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "10399180",
   "metadata": {},
   "outputs": [],
   "source": [
    "developer_prompt = \"\"\"\n",
    "You're a course teaching assistant. \n",
    "You're given a question from a course student and your task is to answer it.\n",
    "\n",
    "Use FAQ if your own knowledge is not sufficient to answer the question.\n",
    "When using FAQ, perform deep topic exploration: make one request to FAQ,\n",
    "and then based on the results, make more requests.\n",
    "\n",
    "At the end of each response, ask the user a follow up question based on your answer.\n",
    "\"\"\".strip()\n",
    "\n",
    "chat_messages = [\n",
    "    {\"role\": \"developer\", \"content\": developer_prompt},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ae070809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function_call: ResponseFunctionToolCall(arguments='{\"query\":\"capstone project tips\"}', call_id='call_og57mj8Hs7NF12NYwn3FquHg', name='search', type='function_call', id='fc_68782e91b8e0819988c831521aae5f0109e146ab3836cdeb', status='completed')\n",
      "\n",
      "To do well on your capstone project, consider the following tips:\n",
      "\n",
      "1. **Understand Evaluation Criteria**: Your project will be evaluated by peer reviewers based on specific guidelines. Familiarize yourself with these criteria to align your project accordingly.\n",
      "\n",
      "2. **Use Your Preferred Tools**: You have the flexibility to use any tools you feel comfortable with. This means you can select technologies that you are proficient in or that align with your project's needs.\n",
      "\n",
      "3. **Manage Your Time**: There’s only one project submission for this course, but remember, you have two attempts. If you face challenges, you can use the second attempt to improve upon or complete your project.\n",
      "\n",
      "4. **Engage with Peers**: Since you will also be grading projects from your peers, engage with your fellow students. This will not only help you gain insights into potential improvements for your project but also familiarize you with different perspectives and ideas.\n",
      "\n",
      "5. **Ask Questions**: If you're encountering technical issues (e.g., related to project setup in GCP), don't hesitate to seek help either from forums, mentors, or the FAQ resources.\n",
      "\n",
      "Have you thought about what specific topic or technology you want to focus on for your capstone project?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "while True: # main Q&A loop\n",
    "    question = input() # How do I do my best for module 1?\n",
    "    if question == 'stop':\n",
    "        break\n",
    "\n",
    "    message = {\"role\": \"user\", \"content\": question}\n",
    "    chat_messages.append(message)\n",
    "\n",
    "    while True: # request-response loop - query API till get a message\n",
    "        response = client.responses.create(\n",
    "            model='gpt-4o-mini',\n",
    "            input=chat_messages,\n",
    "            tools=tools\n",
    "        )\n",
    "\n",
    "        has_messages = False\n",
    "        \n",
    "        for entry in response.output:\n",
    "            chat_messages.append(entry)\n",
    "        \n",
    "            if entry.type == 'function_call':      \n",
    "                print('function_call:', entry)\n",
    "                print()\n",
    "                result = do_call(entry)\n",
    "                chat_messages.append(result)\n",
    "            elif entry.type == 'message':\n",
    "                print(entry.content[0].text)\n",
    "                print()\n",
    "                has_messages = True\n",
    "\n",
    "        if has_messages:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4ff47109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shorten(text, max_length=50):\n",
    "    if len(text) <= max_length:\n",
    "        return text\n",
    "\n",
    "def display_function_call(entry, result):\n",
    "    call_html = f\"\"\"\n",
    "        <details>\n",
    "        <summary>Function call: <tt>{entry.name}({shorten(entry.arguments)})</tt></summary>\n",
    "        <div>\n",
    "            <b>Call</b>\n",
    "            <pre>{entry}</pre>\n",
    "        </div>\n",
    "        <div>\n",
    "            <b>Output</b>\n",
    "            <pre>{result['output']}</pre>\n",
    "        </div>\n",
    "        \n",
    "        </details>\n",
    "    \"\"\"\n",
    "    display(HTML(call_html))\n",
    "\n",
    "def display_response(entry):\n",
    "    response_html = markdown.markdown(entry.content[0].text)\n",
    "    html = f\"\"\"\n",
    "        <div>\n",
    "            <div><b>Assistant:</b></div>\n",
    "            <div>{response_html}</div>\n",
    "        </div>\n",
    "    \"\"\"\n",
    "    display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6bec6ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <details>\n",
       "        <summary>Function call: <tt>search({\"query\":\"capstone project tips\"})</tt></summary>\n",
       "        <div>\n",
       "            <b>Call</b>\n",
       "            <pre>ResponseFunctionToolCall(arguments='{\"query\":\"capstone project tips\"}', call_id='call_rDYFZMORGr82ZqmmoCejJykm', name='search', type='function_call', id='fc_68782ea9b0288198a855c1c8babaf8f103efc9b9dbec14b7', status='completed')</pre>\n",
       "        </div>\n",
       "        <div>\n",
       "            <b>Output</b>\n",
       "            <pre>[\n",
       "  {\n",
       "    \"text\": \"Each submitted project will be evaluated by 3 (three) randomly assigned students that have also submitted the project.\\nYou will also be responsible for grading the projects from 3 fellow students yourself. Please be aware that: not complying to this rule also implies you failing to achieve the Certificate at the end of the course.\\nThe final grade you get will be the median score of the grades you get from the peer reviewers.\\nAnd of course, the peer review criteria for evaluating or being evaluated must follow the guidelines defined here.\",\n",
       "    \"section\": \"Project\",\n",
       "    \"question\": \"How is my capstone project going to be evaluated?\",\n",
       "    \"course\": \"data-engineering-zoomcamp\",\n",
       "    \"_id\": 395\n",
       "  },\n",
       "  {\n",
       "    \"text\": \"There is only ONE project for this Zoomcamp. You do not need to submit or create two projects. There are simply TWO chances to pass the course. You can use the Second Attempt if you a) fail the first attempt b) do not have the time due to other engagements such as holiday or sickness etc. to enter your project into the first attempt.\",\n",
       "    \"section\": \"Project\",\n",
       "    \"question\": \"Project 1 & Project 2\",\n",
       "    \"course\": \"data-engineering-zoomcamp\",\n",
       "    \"_id\": 396\n",
       "  },\n",
       "  {\n",
       "    \"text\": \"Yes, you can use any tool you want for your project.\",\n",
       "    \"section\": \"General course-related questions\",\n",
       "    \"question\": \"Can I use Airflow instead for my final project?\",\n",
       "    \"course\": \"data-engineering-zoomcamp\",\n",
       "    \"_id\": 32\n",
       "  },\n",
       "  {\n",
       "    \"text\": \"If you receive the error: \\u201cError 403: The project to be billed is associated with an absent billing account., accountDisabled\\u201d It is most likely because you did not enter YOUR project ID. The snip below is from video 1.3.2\\nThe value you enter here will be unique to each student. You can find this value on your GCP Dashboard when you login.\\nAshish Agrawal\\nAnother possibility is that you have not linked your billing account to your current project\",\n",
       "    \"section\": \"Module 1: Docker and Terraform\",\n",
       "    \"question\": \"GCP - The project to be billed is associated with an absent billing account\",\n",
       "    \"course\": \"data-engineering-zoomcamp\",\n",
       "    \"_id\": 128\n",
       "  },\n",
       "  {\n",
       "    \"text\": \"It asked me to create a project. This should be done from the cloud console. So maybe we don\\u2019t need this FAQ.\\nWARNING: Project creation failed: HttpError accessing <https://cloudresourcemanager.googleapis.com/v1/projects?alt=json>: response: <{'vtpep_pickup_datetimeary': 'Origin, X-Origin, Referer', 'content-type': 'application/json; charset=UTF-8', 'content-encoding': 'gzip', 'date': 'Mon, 24 Jan 2022 19:29:12 GMT', 'server': 'ESF', 'cache-control': 'private', 'x-xss-protection': '0', 'x-frame-options': 'SAMEORIGIN', 'x-content-type-options': 'nosniff', 'server-timing': 'gfet4t7; dur=189', 'alt-svc': 'h3=\\\":443\\\"; ma=2592000,h3-29=\\\":443\\\"; ma=2592000,h3-Q050=\\\":443\\\"; ma=2592000,h3-Q046=\\\":443\\\"; ma=2592000,h3-Q043=\\\":443\\\"; ma=2592000,quic=\\\":443\\\"; ma=2592000; v=\\\"46,43\\\"', 'transfer-encoding': 'chunked', 'status': 409}>, content <{\\n\\\"error\\\": {\\n\\\"code\\\": 409,\\n\\\"message\\\": \\\"Requested entity alreadytpep_pickup_datetime exists\\\",\\n\\\"status\\\": \\\"ALREADY_EXISTS\\\"\\n}\\n}\\nFrom Stackoverflow: https://stackoverflow.com/questions/52561383/gcloud-cli-cannot-create-project-the-project-id-you-specified-is-already-in-us?rq=1\\nProject IDs are unique across all projects. That means if any user ever had a project with that ID, you cannot use it. testproject is pretty common, so it's not surprising it's already taken.\",\n",
       "    \"section\": \"Module 1: Docker and Terraform\",\n",
       "    \"question\": \"GCP - Project creation failed: HttpError accessing \\u2026 Requested entity alreadytpep_pickup_datetime exists\",\n",
       "    \"course\": \"data-engineering-zoomcamp\",\n",
       "    \"_id\": 127\n",
       "  }\n",
       "]</pre>\n",
       "        </div>\n",
       "        \n",
       "        </details>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <div><b>Assistant:</b></div>\n",
       "            <div><p>To excel in your capstone project, here are some essential tips:</p>\n",
       "<ol>\n",
       "<li>\n",
       "<p><strong>Understand the Requirements</strong>: Carefully read the guidelines and criteria set for the project. Ensure you know what is expected in terms of deliverables.</p>\n",
       "</li>\n",
       "<li>\n",
       "<p><strong>Choose the Right Tools</strong>: Feel free to use any tools you're comfortable with; this flexibility can enhance your project's effectiveness. For example, if you're familiar with Airflow, you can definitely use it.</p>\n",
       "</li>\n",
       "<li>\n",
       "<p><strong>Plan Your Time Wisely</strong>: Develop a timeline for your project. Make sure to allocate time for each stage, including research, development, testing, and documentation.</p>\n",
       "</li>\n",
       "<li>\n",
       "<p><strong>Engage with Peers</strong>: Remember that your project will be peer-reviewed. Engaging with fellow students can give you valuable feedback and different perspectives.</p>\n",
       "</li>\n",
       "<li>\n",
       "<p><strong>Submit Early</strong>: If possible, aim to submit your project ahead of the deadline. This will give you some breathing room to handle any unforeseen issues.</p>\n",
       "</li>\n",
       "<li>\n",
       "<p><strong>Review Peer Projects</strong>: Look at projects from peers for inspiration and insight into areas where you might improve your own work.</p>\n",
       "</li>\n",
       "</ol>\n",
       "<p>Staying organized and proactive will help you achieve a high-quality project. </p>\n",
       "<p>What specific area of your capstone project do you feel you need the most help with?</p></div>\n",
       "        </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat ended.\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "import markdown # pip install markdown\n",
    "\n",
    "\n",
    "developer_prompt = \"\"\"\n",
    "You're a course teaching assistant. \n",
    "You're given a question from a course student and your task is to answer it.\n",
    "\n",
    "Use FAQ if your own knowledge is not sufficient to answer the question.\n",
    "\n",
    "At the end of each response, ask the user a follow up question based on your answer.\n",
    "\"\"\".strip()\n",
    "\n",
    "chat_messages = [\n",
    "    {\"role\": \"developer\", \"content\": developer_prompt},\n",
    "]\n",
    "\n",
    "# Chat loop\n",
    "while True:\n",
    "    question = input() # How do I do my best for module 1?\n",
    "    \n",
    "    if question.strip().lower() == 'stop':\n",
    "        print(\"Chat ended.\")\n",
    "        break\n",
    "    print()\n",
    "\n",
    "    message = {\"role\": \"user\", \"content\": question}\n",
    "    chat_messages.append(message)\n",
    "\n",
    "    while True:  # inner request loop\n",
    "        response = client.responses.create(\n",
    "            model='gpt-4o-mini',\n",
    "            input=chat_messages,\n",
    "            tools=tools\n",
    "        )\n",
    "\n",
    "        has_messages = False\n",
    "\n",
    "        for entry in response.output:\n",
    "            chat_messages.append(entry)\n",
    "\n",
    "            if entry.type == \"function_call\":\n",
    "                result = do_call(entry)\n",
    "                chat_messages.append(result)\n",
    "                display_function_call(entry, result)\n",
    "\n",
    "            elif entry.type == \"message\":\n",
    "                display_response(entry)\n",
    "                has_messages = True\n",
    "\n",
    "        if has_messages:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0bb30472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_entry(question, answer):\n",
    "    doc = {\n",
    "        'question': question,\n",
    "        'text': answer,\n",
    "        'section': 'user added',\n",
    "        'course': 'data-engineering-zoomcamp'\n",
    "    }\n",
    "    index.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "99f972ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_entry_description = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"add_entry\",\n",
    "    \"description\": \"Add an entry to the FAQ database\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"question\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question to be added to the FAQ database\",\n",
    "            },\n",
    "            \"answer\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The answer to the question\",\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"question\", \"answer\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3e667bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-07-16 12:32:29--  https://raw.githubusercontent.com/alexeygrigorev/rag-agents-workshop/refs/heads/main/chat_assistant.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3485 (3.4K) [text/plain]\n",
      "Saving to: ‘chat_assistant.py’\n",
      "\n",
      "chat_assistant.py   100%[===================>]   3.40K  --.-KB/s    in 0.001s  \n",
      "\n",
      "2025-07-16 12:32:29 (3.71 MB/s) - ‘chat_assistant.py’ saved [3485/3485]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/alexeygrigorev/rag-agents-workshop/refs/heads/main/chat_assistant.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "43b3c2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chat_assistant\n",
    "\n",
    "tools = chat_assistant.Tools()\n",
    "tools.add_tool(search, search_tool)\n",
    "\n",
    "tools.get_tools()\n",
    "\n",
    "developer_prompt = \"\"\"\n",
    "You're a course teaching assistant. \n",
    "You're given a question from a course student and your task is to answer it.\n",
    "\n",
    "Use FAQ if your own knowledge is not sufficient to answer the question.\n",
    "\n",
    "At the end of each response, ask the user a follow up question based on your answer.\n",
    "\"\"\".strip()\n",
    "\n",
    "chat_interface = chat_assistant.ChatInterface()\n",
    "\n",
    "chat = chat_assistant.ChatAssistant(\n",
    "    tools=tools,\n",
    "    developer_prompt=developer_prompt,\n",
    "    chat_interface=chat_interface,\n",
    "    client=client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f9b7653a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>search({\"query\":\"capstone project tips\"})</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>ResponseFunctionToolCall(arguments='{\"query\":\"capstone project tips\"}', call_id='call_yfk7aQXLIgqPHj3oglyYuCwy', name='search', type='function_call', id='fc_68782ed577d0819a89c3efa36bd0e80e083f70bf56bda69d', status='completed')</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>[\n",
       "  {\n",
       "    \"text\": \"Each submitted project will be evaluated by 3 (three) randomly assigned students that have also submitted the project.\\nYou will also be responsible for grading the projects from 3 fellow students yourself. Please be aware that: not complying to this rule also implies you failing to achieve the Certificate at the end of the course.\\nThe final grade you get will be the median score of the grades you get from the peer reviewers.\\nAnd of course, the peer review criteria for evaluating or being evaluated must follow the guidelines defined here.\",\n",
       "    \"section\": \"Project\",\n",
       "    \"question\": \"How is my capstone project going to be evaluated?\",\n",
       "    \"course\": \"data-engineering-zoomcamp\",\n",
       "    \"_id\": 395\n",
       "  },\n",
       "  {\n",
       "    \"text\": \"There is only ONE project for this Zoomcamp. You do not need to submit or create two projects. There are simply TWO chances to pass the course. You can use the Second Attempt if you a) fail the first attempt b) do not have the time due to other engagements such as holiday or sickness etc. to enter your project into the first attempt.\",\n",
       "    \"section\": \"Project\",\n",
       "    \"question\": \"Project 1 & Project 2\",\n",
       "    \"course\": \"data-engineering-zoomcamp\",\n",
       "    \"_id\": 396\n",
       "  },\n",
       "  {\n",
       "    \"text\": \"Yes, you can use any tool you want for your project.\",\n",
       "    \"section\": \"General course-related questions\",\n",
       "    \"question\": \"Can I use Airflow instead for my final project?\",\n",
       "    \"course\": \"data-engineering-zoomcamp\",\n",
       "    \"_id\": 32\n",
       "  },\n",
       "  {\n",
       "    \"text\": \"If you receive the error: \\u201cError 403: The project to be billed is associated with an absent billing account., accountDisabled\\u201d It is most likely because you did not enter YOUR project ID. The snip below is from video 1.3.2\\nThe value you enter here will be unique to each student. You can find this value on your GCP Dashboard when you login.\\nAshish Agrawal\\nAnother possibility is that you have not linked your billing account to your current project\",\n",
       "    \"section\": \"Module 1: Docker and Terraform\",\n",
       "    \"question\": \"GCP - The project to be billed is associated with an absent billing account\",\n",
       "    \"course\": \"data-engineering-zoomcamp\",\n",
       "    \"_id\": 128\n",
       "  },\n",
       "  {\n",
       "    \"text\": \"It asked me to create a project. This should be done from the cloud console. So maybe we don\\u2019t need this FAQ.\\nWARNING: Project creation failed: HttpError accessing <https://cloudresourcemanager.googleapis.com/v1/projects?alt=json>: response: <{'vtpep_pickup_datetimeary': 'Origin, X-Origin, Referer', 'content-type': 'application/json; charset=UTF-8', 'content-encoding': 'gzip', 'date': 'Mon, 24 Jan 2022 19:29:12 GMT', 'server': 'ESF', 'cache-control': 'private', 'x-xss-protection': '0', 'x-frame-options': 'SAMEORIGIN', 'x-content-type-options': 'nosniff', 'server-timing': 'gfet4t7; dur=189', 'alt-svc': 'h3=\\\":443\\\"; ma=2592000,h3-29=\\\":443\\\"; ma=2592000,h3-Q050=\\\":443\\\"; ma=2592000,h3-Q046=\\\":443\\\"; ma=2592000,h3-Q043=\\\":443\\\"; ma=2592000,quic=\\\":443\\\"; ma=2592000; v=\\\"46,43\\\"', 'transfer-encoding': 'chunked', 'status': 409}>, content <{\\n\\\"error\\\": {\\n\\\"code\\\": 409,\\n\\\"message\\\": \\\"Requested entity alreadytpep_pickup_datetime exists\\\",\\n\\\"status\\\": \\\"ALREADY_EXISTS\\\"\\n}\\n}\\nFrom Stackoverflow: https://stackoverflow.com/questions/52561383/gcloud-cli-cannot-create-project-the-project-id-you-specified-is-already-in-us?rq=1\\nProject IDs are unique across all projects. That means if any user ever had a project with that ID, you cannot use it. testproject is pretty common, so it's not surprising it's already taken.\",\n",
       "    \"section\": \"Module 1: Docker and Terraform\",\n",
       "    \"question\": \"GCP - Project creation failed: HttpError accessing \\u2026 Requested entity alreadytpep_pickup_datetime exists\",\n",
       "    \"course\": \"data-engineering-zoomcamp\",\n",
       "    \"_id\": 127\n",
       "  }\n",
       "]</pre>\n",
       "            </div>\n",
       "            \n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>To do well on your capstone project, consider the following tips based on common practices:</p>\n",
       "<ol>\n",
       "<li>\n",
       "<p><strong>Understand Criteria</strong>: Familiarize yourself with the grading criteria. Your project will be evaluated by peer reviews, and understanding these guidelines will help you align your work to what reviewers are looking for.</p>\n",
       "</li>\n",
       "<li>\n",
       "<p><strong>Choose Appropriate Tools</strong>: You can use any tools you prefer for your project. Pick tools that you are comfortable with and that suit the project requirements.</p>\n",
       "</li>\n",
       "<li>\n",
       "<p><strong>Project Planning</strong>: Create a detailed plan that outlines your project scope, objectives, timeline, and milestones. This will help you stay organized and focused.</p>\n",
       "</li>\n",
       "<li>\n",
       "<p><strong>Engage with Peers</strong>: Collaborate or discuss ideas with fellow students. Their insights can enhance your project and provide additional resources or perspectives.</p>\n",
       "</li>\n",
       "<li>\n",
       "<p><strong>Seek Feedback</strong>: Don’t hesitate to ask for feedback throughout the project. This could be from instructors, classmates, or through online forums.</p>\n",
       "</li>\n",
       "<li>\n",
       "<p><strong>Test Thoroughly</strong>: Ensure your project works as intended by conducting thorough testing. Anticipate and resolve potential issues before submission.</p>\n",
       "</li>\n",
       "<li>\n",
       "<p><strong>Document Your Work</strong>: Maintain clear documentation of your project process, decisions made, and any challenges faced. Good documentation can greatly assist your peer reviewers.</p>\n",
       "</li>\n",
       "</ol>\n",
       "<p>Would you like to discuss any specific area of your project, such as planning or tools?</p></div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat ended.\n"
     ]
    }
   ],
   "source": [
    "chat.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ae431105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'name': 'search',\n",
       "  'description': 'Search the FAQ database',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'query': {'type': 'string',\n",
       "     'description': 'Search query text to look up in the course FAQ.'}},\n",
       "   'required': ['query'],\n",
       "   'additionalProperties': False}},\n",
       " {'type': 'function',\n",
       "  'name': 'add_entry',\n",
       "  'description': 'Add an entry to the FAQ database',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'question': {'type': 'string',\n",
       "     'description': 'The question to be added to the FAQ database'},\n",
       "    'answer': {'type': 'string', 'description': 'The answer to the question'}},\n",
       "   'required': ['question', 'answer'],\n",
       "   'additionalProperties': False}}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools.add_tool(add_entry, add_entry_description)\n",
    "tools.get_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "321fb99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>search({\"query\":\"instalar Kafka\"})</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>ResponseFunctionToolCall(arguments='{\"query\":\"instalar Kafka\"}', call_id='call_69pzFs49TDsOzz2FJuW9mHse', name='search', type='function_call', id='fc_68782eeffdec819a9e29be6f6bf1b1ba041ecf462c8544e8', status='completed')</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>[\n",
       "  {\n",
       "    \"text\": \"If you have this error, it most likely that your kafka broker docker container is not working.\\nUse docker ps to confirm\\nThen in the docker compose yaml file folder, run docker compose up -d to start all the instances.\",\n",
       "    \"section\": \"Module 6: streaming with kafka\",\n",
       "    \"question\": \"kafka.errors.NoBrokersAvailable: NoBrokersAvailable\",\n",
       "    \"course\": \"data-engineering-zoomcamp\",\n",
       "    \"_id\": 379\n",
       "  },\n",
       "  {\n",
       "    \"text\": \"tip:As the videos have low audio so I downloaded them and used VLC media player with putting the audio to the max 200% of original audio and the audio became quite good or try to use auto caption generated on Youtube directly.\\nKafka Python Videos - Rides.csv\\nThere is no clear explanation of the rides.csv data that the producer.py python programs use. You can find that here https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/2bd33e89906181e424f7b12a299b70b19b7cfcd5/week_6_stream_processing/python/resources/rides.csv.\",\n",
       "    \"section\": \"Module 6: streaming with kafka\",\n",
       "    \"question\": \"Kafka- python videos have low audio and hard to follow up\",\n",
       "    \"course\": \"data-engineering-zoomcamp\",\n",
       "    \"_id\": 378\n",
       "  },\n",
       "  {\n",
       "    \"text\": \"confluent-kafka: `pip install confluent-kafka` or `conda install conda-forge::python-confluent-kafka`\\nfastavro: pip install fastavro\\nAbhirup Ghosh\\nCan install Faust Library for Module 6 Python Version due to dependency conflicts?\\nThe Faust repository and library is no longer maintained - https://github.com/robinhood/faust\\nIf you do not know Java, you now have the option to follow the Python Videos 6.13 & 6.14 here https://www.youtube.com/watch?v=BgAlVknDFlQ&list=PL3MmuxUbc_hJed7dXYoJw8DoCuVHhGEQb&index=80  and follow the RedPanda Python version here https://github.com/DataTalksClub/data-engineering-zoomcamp/tree/main/06-streaming/python/redpanda_example - NOTE: I highly recommend watching the Java videos to understand the concept of streaming but you can skip the coding parts - all will become clear when you get to the Python videos and RedPanda files.\",\n",
       "    \"section\": \"Module 6: streaming with kafka\",\n",
       "    \"question\": \"Python Kafka: Installing dependencies for python3 06-streaming/python/avro_example/producer.py\",\n",
       "    \"course\": \"data-engineering-zoomcamp\",\n",
       "    \"_id\": 388\n",
       "  },\n",
       "  {\n",
       "    \"text\": \"In my set up, all of the dependencies listed in gradle.build were not installed in <project_name>-1.0-SNAPSHOT.jar.\\nSolution:\\nIn build.gradle file, I added the following at the end:\\nshadowJar {\\narchiveBaseName = \\\"java-kafka-rides\\\"\\narchiveClassifier = ''\\n}\\nAnd then in the command line ran \\u2018gradle shadowjar\\u2019, and run the script from java-kafka-rides-1.0-SNAPSHOT.jar created by the shadowjar\",\n",
       "    \"section\": \"Module 6: streaming with kafka\",\n",
       "    \"question\": \"Java Kafka: <project_name>-1.0-SNAPSHOT.jar errors: package xxx does not exist even after gradle build\",\n",
       "    \"course\": \"data-engineering-zoomcamp\",\n",
       "    \"_id\": 387\n",
       "  },\n",
       "  {\n",
       "    \"text\": \"For example, when running JsonConsumer.java, got:\\nConsuming form kafka started\\nRESULTS:::0\\nRESULTS:::0\\nRESULTS:::0\\nOr when running JsonProducer.java, got:\\nException in thread \\\"main\\\" java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.SaslAuthenticationException: Authentication failed\\nSolution:\\nMake sure in the scripts in src/main/java/org/example/ that you are running (e.g. JsonConsumer.java, JsonProducer.java), the StreamsConfig.BOOTSTRAP_SERVERS_CONFIG is the correct server url (e.g. europe-west3 from example vs europe-west2)\\nMake sure cluster key and secrets are updated in src/main/java/org/example/Secrets.java (KAFKA_CLUSTER_KEY and KAFKA_CLUSTER_SECRET)\",\n",
       "    \"section\": \"Module 6: streaming with kafka\",\n",
       "    \"question\": \"Java Kafka: When running the producer/consumer/etc java scripts, no results retrieved or no message sent\",\n",
       "    \"course\": \"data-engineering-zoomcamp\",\n",
       "    \"_id\": 390\n",
       "  }\n",
       "]</pre>\n",
       "            </div>\n",
       "            \n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>Para instalar Kafka, puedes seguir estos pasos generales:</p>\n",
       "<ol>\n",
       "<li>\n",
       "<p><strong>Descargar Kafka</strong>: Ve al <a href=\"https://kafka.apache.org/downloads\">sitio oficial de Apache Kafka</a> y descarga la última versión.</p>\n",
       "</li>\n",
       "<li>\n",
       "<p><strong>Descomprimir el archivo</strong>: Extrae el contenido del archivo descargado en un directorio de tu elección.</p>\n",
       "</li>\n",
       "<li>\n",
       "<p><strong>Instalar Java</strong>: Asegúrate de tener Java instalado en tu sistema, ya que Kafka está escrito en Java. Puedes verificar si está instalado con el comando:\n",
       "   <code>bash\n",
       "   java -version</code></p>\n",
       "</li>\n",
       "<li>\n",
       "<p><strong>Iniciar Zookeeper</strong>: Antes de ejecutar Kafka, necesitas iniciar Zookeeper, que Kafka utiliza para mantener el estado. Puedes hacerlo con el siguiente comando en la terminal:\n",
       "   <code>bash\n",
       "   bin/zookeeper-server-start.sh config/zookeeper.properties</code></p>\n",
       "</li>\n",
       "<li>\n",
       "<p><strong>Iniciar Kafka</strong>: En otra terminal, inicia el servidor de Kafka usando:\n",
       "   <code>bash\n",
       "   bin/kafka-server-start.sh config/server.properties</code></p>\n",
       "</li>\n",
       "<li>\n",
       "<p><strong>Crear un tema</strong>: Después de que Kafka esté funcionando, puedes crear un nuevo tema con el siguiente command:\n",
       "   <code>bash\n",
       "   bin/kafka-topics.sh --create --topic my-topic --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1</code></p>\n",
       "</li>\n",
       "<li>\n",
       "<p><strong>Publicar y consumir mensajes</strong>: Usa los clientes de línea de comandos para enviar y recibir mensajes.</p>\n",
       "</li>\n",
       "</ol>\n",
       "<p>Si necesitas más ayuda o un problema específico con la instalación, no dudes en preguntar.</p>\n",
       "<p>¿Tienes alguna preferencia sobre si deseas usar la versión de Kafka en Docker o la instalación estándar?</p></div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>add_entry({\"question\":\"How to install Kafka?\",\"answer\":\"1...)</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>ResponseFunctionToolCall(arguments='{\"question\":\"How to install Kafka?\",\"answer\":\"1. **Download Kafka**: Go to the [Apache Kafka official site](https://kafka.apache.org/downloads) and download the latest version.\\\\n\\\\n2. **Unzip the file**: Extract the contents of the downloaded file to a directory of your choice.\\\\n\\\\n3. **Install Java**: Ensure you have Java installed on your system since Kafka is written in Java. You can check if it\\'s installed with the command:\\\\n   ```bash\\\\n   java -version\\\\n   ```\\\\n\\\\n4. **Start Zookeeper**: Before running Kafka, you need to start Zookeeper, which Kafka uses to maintain state. You can do this with the following command in your terminal:\\\\n   ```bash\\\\n   bin/zookeeper-server-start.sh config/zookeeper.properties\\\\n   ```\\\\n\\\\n5. **Start Kafka**: In another terminal, start the Kafka server using:\\\\n   ```bash\\\\n   bin/kafka-server-start.sh config/server.properties\\\\n   ```\\\\n\\\\n6. **Create a topic**: After Kafka is running, you can create a new topic with the following command:\\\\n   ```bash\\\\n   bin/kafka-topics.sh --create --topic my-topic --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1\\\\n   ```\\\\n\\\\n7. **Publish and consume messages**: Use the command-line clients to send and receive messages.\"}', call_id='call_ZQoBXu7BcsZ8EtX3m6Mg2cwL', name='add_entry', type='function_call', id='fc_68782f01ecc4819a813c06a33d175aa8041ecf462c8544e8', status='completed')</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>null</pre>\n",
       "            </div>\n",
       "            \n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>He añadido la información sobre cómo instalar Kafka a la FAQ. Si necesitas más detalles o tienes otra pregunta, ¡háznoslo saber!</p>\n",
       "<p>¿Hay algo más específico sobre Kafka que te gustaría aprender?</p></div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat ended.\n"
     ]
    }
   ],
   "source": [
    "chat.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3fd09fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'How to install Kafka?',\n",
       " 'text': \"1. **Download Kafka**: Go to the [Apache Kafka official site](https://kafka.apache.org/downloads) and download the latest version.\\n\\n2. **Unzip the file**: Extract the contents of the downloaded file to a directory of your choice.\\n\\n3. **Install Java**: Ensure you have Java installed on your system since Kafka is written in Java. You can check if it's installed with the command:\\n   ```bash\\n   java -version\\n   ```\\n\\n4. **Start Zookeeper**: Before running Kafka, you need to start Zookeeper, which Kafka uses to maintain state. You can do this with the following command in your terminal:\\n   ```bash\\n   bin/zookeeper-server-start.sh config/zookeeper.properties\\n   ```\\n\\n5. **Start Kafka**: In another terminal, start the Kafka server using:\\n   ```bash\\n   bin/kafka-server-start.sh config/server.properties\\n   ```\\n\\n6. **Create a topic**: After Kafka is running, you can create a new topic with the following command:\\n   ```bash\\n   bin/kafka-topics.sh --create --topic my-topic --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1\\n   ```\\n\\n7. **Publish and consume messages**: Use the command-line clients to send and receive messages.\",\n",
       " 'section': 'user added',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.docs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8550dc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai import Agent, RunContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ee9fb89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_agent = Agent(  \n",
    "    'openai:gpt-4o-mini',\n",
    "    system_prompt=developer_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8ad841ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "\n",
    "@chat_agent.tool\n",
    "def search_tool(ctx: RunContext, query: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Search the FAQ for relevant entries matching the query.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    query : str\n",
    "        The search query string provided by the user.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        A list of search results (up to 5), each containing relevance information \n",
    "        and associated output IDs.\n",
    "    \"\"\"\n",
    "    print(f\"search('{query}')\")\n",
    "    return search(query)\n",
    "\n",
    "\n",
    "@chat_agent.tool\n",
    "def add_entry_tool(ctx: RunContext, question: str, answer: str) -> None:\n",
    "    \"\"\"\n",
    "    Add a new question-answer entry to FAQ.\n",
    "\n",
    "    This function creates a document with the given question and answer, \n",
    "    tagging it as user-added content.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    question : str\n",
    "        The question text to be added to the index.\n",
    "\n",
    "    answer : str\n",
    "        The answer or explanation corresponding to the question.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    return add_entry(question, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "285635a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search('Can I join the course now?')\n",
      "Yes, you can still join the course even if you missed the start date! You are eligible to submit homeworks without registering. However, keep in mind that there will be deadlines for the final projects, so it's best not to leave everything until the last minute.\n",
      "\n",
      "Would you like to know more about the course schedule or how to access the materials?\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"I just discovered the course. Can I join now?\"\n",
    "agent_run = await chat_agent.run(user_prompt)\n",
    "print(agent_run.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e8f0eb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started server with command: python weather_server.py\n",
      "Sending initialize request...\n",
      "Initialize response: {'protocolVersion': '2024-11-05', 'capabilities': {'experimental': {}, 'prompts': {'listChanged': False}, 'resources': {'subscribe': False, 'listChanged': False}, 'tools': {'listChanged': True}}, 'serverInfo': {'name': 'Demo 🚀', 'version': '1.11.0'}}\n",
      "Sending initialized notification...\n",
      "Handshake completed successfully\n"
     ]
    }
   ],
   "source": [
    "import mcp_client\n",
    "\n",
    "our_mcp_client = mcp_client.MCPClient([\"python\", \"weather_server.py\"])\n",
    "\n",
    "our_mcp_client.start_server()\n",
    "our_mcp_client.initialize()\n",
    "our_mcp_client.initialized()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "72fddd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving available tools...\n",
      "Available tools: ['get_weather', 'set_weather']\n",
      "Calling tool 'get_weather' with arguments: {'city': 'Berlin'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'content': [{'type': 'text', 'text': '20.0'}],\n",
       " 'structuredContent': {'result': 20.0},\n",
       " 'isError': False}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_mcp_client.get_tools()\n",
    "our_mcp_client.call_tool('get_weather', {'city': 'Berlin'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "06c9e0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class MCPTools:\n",
    "    def __init__(self, mcp_client):\n",
    "        self.mcp_client = mcp_client\n",
    "        self.tools = None\n",
    "    \n",
    "    def get_tools(self):\n",
    "        if self.tools is None:\n",
    "            mcp_tools = self.mcp_client.get_tools()\n",
    "            self.tools = convert_tools_list(mcp_tools)\n",
    "        return self.tools\n",
    "\n",
    "    def function_call(self, tool_call_response):\n",
    "        function_name = tool_call_response.name\n",
    "        arguments = json.loads(tool_call_response.arguments)\n",
    "\n",
    "        result = self.mcp_client.call_tool(function_name, arguments)\n",
    "\n",
    "        return {\n",
    "            \"type\": \"function_call_output\",\n",
    "            \"call_id\": tool_call_response.call_id,\n",
    "            \"output\": json.dumps(result, indent=2),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3ae82843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started server with command: python weather_server.py\n",
      "Sending initialize request...\n",
      "Initialize response: {'protocolVersion': '2024-11-05', 'capabilities': {'experimental': {}, 'prompts': {'listChanged': False}, 'resources': {'subscribe': False, 'listChanged': False}, 'tools': {'listChanged': True}}, 'serverInfo': {'name': 'Demo 🚀', 'version': '1.11.0'}}\n",
      "Sending initialized notification...\n",
      "Handshake completed successfully\n",
      "Retrieving available tools...\n",
      "Available tools: ['get_weather', 'set_weather']\n",
      "Calling tool 'get_weather' with arguments: {'city': 'Berlin'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>get_weather({\"city\":\"Berlin\"})</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>ResponseFunctionToolCall(arguments='{\"city\":\"Berlin\"}', call_id='call_QroXYtz2VNaEw3sfRxRqZMPd', name='get_weather', type='function_call', id='fc_68782f6c46448199ab7742b8677effc608fde2456012c01c', status='completed')</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>{\n",
       "  \"content\": [\n",
       "    {\n",
       "      \"type\": \"text\",\n",
       "      \"text\": \"20.0\"\n",
       "    }\n",
       "  ],\n",
       "  \"structuredContent\": {\n",
       "    \"result\": 20.0\n",
       "  },\n",
       "  \"isError\": false\n",
       "}</pre>\n",
       "            </div>\n",
       "            \n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>The current temperature in Berlin is 20.0°C. If you need more details, feel free to ask!</p></div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat ended.\n"
     ]
    }
   ],
   "source": [
    "our_mcp_client = mcp_client.MCPClient([\"python\", \"weather_server.py\"])\n",
    "\n",
    "our_mcp_client.start_server()\n",
    "our_mcp_client.initialize()\n",
    "our_mcp_client.initialized()\n",
    "\n",
    "mcp_tools = mcp_client.MCPTools(mcp_client=our_mcp_client)\n",
    "\n",
    "\n",
    "developer_prompt = \"\"\"\n",
    "You help users find out the weather in their cities. \n",
    "If they didn't specify a city, ask them. Make sure we always use a city.\n",
    "\"\"\".strip()\n",
    "\n",
    "chat_interface = chat_assistant.ChatInterface()\n",
    "\n",
    "chat = chat_assistant.ChatAssistant(\n",
    "    tools=mcp_tools,\n",
    "    developer_prompt=developer_prompt,\n",
    "    chat_interface=chat_interface,\n",
    "    client=client\n",
    ")\n",
    "\n",
    "chat.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b0fcbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
