{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3ec413ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "df138b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.append.AppendableIndex at 0x777bff2fa020>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from minsearch import AppendableIndex\n",
    "\n",
    "index = AppendableIndex(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")\n",
    "\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "94a60573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5,\n",
    "        output_ids=True\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "507a0583",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<CONTEXT>\n",
    "{context}\n",
    "</CONTEXT>\n",
    "\"\"\".strip()\n",
    "\n",
    "def build_prompt(query, search_results):\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "93e2be7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Cargar .env\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "09505649",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5713e846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To join the course, you need to register before it starts using the provided link. The course begins on January 15th, 2024, at 17:00. Additionally, you can join the course's Telegram channel for announcements and register in DataTalks.Club's Slack to access the relevant channels. Even if you miss the registration deadline, you can still submit homework and participate, but be mindful of the final project deadlines.\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'how do i join the course?'\n",
    "rag(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "764d83c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant.\n",
    "\n",
    "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
    "At the beginning the context is EMPTY.\n",
    "\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<CONTEXT> \n",
    "{context}\n",
    "</CONTEXT>\n",
    "\n",
    "IF you have an acceptable response, proceed to answer, or If CONTEXT is EMPTY and you dont have an accurate answer, you SHOULD use our FAQ database.\n",
    "In this case, use the following output template:\n",
    "\n",
    "{{\n",
    "\"action\": \"SEARCH\",\n",
    "\"reasoning\": \"<add your reasoning here>\"\n",
    "}}\n",
    "\n",
    "If you can answer the QUESTION using CONTEXT, use this template:\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"CONTEXT\"\n",
    "}}\n",
    "\n",
    "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"OWN_KNOWLEDGE\"\n",
    "}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3a0a5ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "At the beginning the context is EMPTY.\n",
      "\n",
      "<QUESTION>\n",
      "how do I run docker on gentoo?\n",
      "</QUESTION>\n",
      "\n",
      "<CONTEXT> \n",
      "EMPTY\n",
      "</CONTEXT>\n",
      "\n",
      "If CONTEXT is EMPTY, you can use our FAQ database.\n",
      "In this case, use the following output template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\"\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"To run Docker on Gentoo, you need to follow these steps: 1. First, ensure that your system is up to date. You can do this by running `emerge --sync` and then `emerge -uDNav world`. 2. Next, install Docker using the following command: `emerge app-emulation/docker`. 3. After the installation, you need to start the Docker service. You can do this by running `/etc/init.d/docker start` and consider adding it to the default runlevel with `rc-update add docker default`. 4. Finally, to be able to run Docker commands without sudo, add your user to the 'docker' group with `gpasswd -a $USER docker`. Log out and back in after doing this. Now you should be able to run Docker commands on your Gentoo system.\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "question = \"how do I run docker on gentoo?\"\n",
    "context = \"EMPTY\"\n",
    "\n",
    "prompt = prompt_template.format(question=question, context=context)\n",
    "print(prompt)\n",
    "\n",
    "answer = llm(prompt)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5191aa7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"To join the course, you typically need to visit the course website or platform where it is offered. Look for a 'Sign Up' or 'Enroll' button, and follow the instructions to create an account or enroll directly. You may also need to provide some personal information and agree to any terms or fees associated with the course.\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "question = \"how do I join the course?\"\n",
    "context = \"EMPTY\"\n",
    "\n",
    "prompt = prompt_template.format(question=question, context=context)\n",
    "answer = llm(prompt)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "192cca17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_context(search_results):\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "\n",
    "    return context.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dcaefd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "At the beginning the context is EMPTY.\n",
      "\n",
      "<QUESTION>\n",
      "how do I join the course?\n",
      "</QUESTION>\n",
      "\n",
      "<CONTEXT> \n",
      "section: General course-related questions\n",
      "question: Course - Can I still join the course after the start date?\n",
      "answer: Yes, even if you don't register, you're still eligible to submit the homeworks.\n",
      "Be aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - When will the course start?\n",
      "answer: The purpose of this document is to capture frequently asked technical questions\n",
      "The exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\n",
      "Subscribe to course public Google Calendar (it works from Desktop only).\n",
      "Register before the course starts using this link.\n",
      "Join the course Telegram channel with announcements.\n",
      "Don’t forget to register in DataTalks.Club's Slack and join the channel.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - Can I follow the course after it finishes?\n",
      "answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\n",
      "You can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Certificate - Can I follow the course in a self-paced mode and get a certificate?\n",
      "answer: No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\n",
      "\n",
      "section: General course-related questions\n",
      "question: How do I use Git / GitHub for this course?\n",
      "answer: After you create a GitHub account, you should clone the course repo to your local machine using the process outlined in this video: Git for Everybody: How to Clone a Repository from GitHub\n",
      "Having this local repository on your computer will make it easy for you to access the instructors’ code and make pull requests (if you want to add your own notes or make changes to the course content).\n",
      "You will probably also create your own repositories that host your notes, versions of your file, to do this. Here is a great tutorial that shows you how to do this: https://www.atlassian.com/git/tutorials/setting-up-a-repository\n",
      "Remember to ignore large database, .csv, and .gz files, and other files that should not be saved to a repository. Use .gitignore for this: https://www.atlassian.com/git/tutorials/saving-changes/gitignore NEVER store passwords or keys in a git repo (even if that repo is set to private).\n",
      "This is also a great resource: https://dangitgit.com/\n",
      "</CONTEXT>\n",
      "\n",
      "If CONTEXT is EMPTY, you can use our FAQ database.\n",
      "In this case, use the following output template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\"\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "search_results = search(question)\n",
    "context = build_context(search_results)\n",
    "prompt = prompt_template.format(question=question, context=context)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4d360e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"To join the course, you need to register before the course starts using the provided registration link. The course begins on January 15th, 2024, at 17:00, so make sure to complete your registration before that date. Additionally, it is beneficial to join the course Telegram channel for announcements and subscribe to the course public Google Calendar for updates.\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "answer = llm(prompt)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "899de870",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "77eeba4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agentic_rag_v1(question):\n",
    "    context = \"EMPTY\"\n",
    "    prompt = prompt_template.format(question=question, context=context)\n",
    "    answer_json = llm(prompt)\n",
    "    answer = json.loads(answer_json)\n",
    "    print(answer)\n",
    "\n",
    "    if answer['action'] == 'SEARCH':\n",
    "        print('need to perform search...')\n",
    "        search_results = search(question)\n",
    "        context = build_context(search_results)\n",
    "        \n",
    "        prompt = prompt_template.format(question=question, context=context)\n",
    "        answer_json = llm(prompt)\n",
    "        answer = json.loads(answer_json)\n",
    "        print(answer)\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "182fcbbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action': 'SEARCH', 'reasoning': 'I do not have specific information about how to join the course in the context provided, so I will refer to the FAQ database to find the answer.'}\n",
      "need to perform search...\n",
      "{'action': 'ANSWER', 'answer': \"To join the course, you need to register before the course starts using the provided link. Even if you register after the start date, you can still participate by submitting homeworks. Make sure to also join the course's Telegram channel and sign up for the Slack channel on DataTalks.Club for announcements and discussions.\", 'source': 'CONTEXT'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'action': 'ANSWER',\n",
       " 'answer': \"To join the course, you need to register before the course starts using the provided link. Even if you register after the start date, you can still participate by submitting homeworks. Make sure to also join the course's Telegram channel and sign up for the Slack channel on DataTalks.Club for announcements and discussions.\",\n",
       " 'source': 'CONTEXT'}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agentic_rag_v1('how do I join the course?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1924b4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action': 'ANSWER', 'answer': \"To patch KDE under FreeBSD, you typically need to download the source code of the version you want to patch. After applying your patch file to the relevant source files, you can use the FreeBSD ports system or the 'make' command to build the software. Here are the steps involved:\\n\\n1. **Obtain the source code**: You can either use the ports collection (`/usr/ports/x11/kde5`) or download the KDE source tarball from the official KDE website.\\n\\n2. **Apply the patch**: Navigate to the directory where the source code resides and apply your patch file using the `patch` command. For example:\\n   ```\\n   patch < /path/to/your/patchfile.patch\\n   ```\\n\\n3. **Compile**: After the patch has been applied, build the package by running:\\n   ```\\n   make install clean\\n   ```\\n\\n4. **Install**: This will compile the code and install the patched version of KDE.\\n\\n5. **Test**: Finally, make sure to test the newly compiled KDE to ensure that everything works as expected.\\n\\nIf you encounter any issues, consult the FreeBSD Handbook or the documentation specific to the KDE version you are working with for further assistance.\", 'source': 'OWN_KNOWLEDGE'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'action': 'ANSWER',\n",
       " 'answer': \"To patch KDE under FreeBSD, you typically need to download the source code of the version you want to patch. After applying your patch file to the relevant source files, you can use the FreeBSD ports system or the 'make' command to build the software. Here are the steps involved:\\n\\n1. **Obtain the source code**: You can either use the ports collection (`/usr/ports/x11/kde5`) or download the KDE source tarball from the official KDE website.\\n\\n2. **Apply the patch**: Navigate to the directory where the source code resides and apply your patch file using the `patch` command. For example:\\n   ```\\n   patch < /path/to/your/patchfile.patch\\n   ```\\n\\n3. **Compile**: After the patch has been applied, build the package by running:\\n   ```\\n   make install clean\\n   ```\\n\\n4. **Install**: This will compile the code and install the patched version of KDE.\\n\\n5. **Test**: Finally, make sure to test the newly compiled KDE to ensure that everything works as expected.\\n\\nIf you encounter any issues, consult the FreeBSD Handbook or the documentation specific to the KDE version you are working with for further assistance.\",\n",
       " 'source': 'OWN_KNOWLEDGE'}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agentic_rag_v1('how patch KDE under FreeBSD?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "20df7eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant.\n",
    "\n",
    "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
    "\n",
    "The CONTEXT is build with the documents from our FAQ database.\n",
    "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
    "from FAQ to and add them to the context.\n",
    "PREVIOUS_ACTIONS contains the actions you already performed.\n",
    "\n",
    "At the beginning the CONTEXT is empty.\n",
    "\n",
    "You can perform the following actions:\n",
    "\n",
    "- Search in the FAQ database to get more data for the CONTEXT\n",
    "- Answer the question using the CONTEXT\n",
    "- Answer the question using your own knowledge\n",
    "\n",
    "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
    "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
    "\n",
    "Don't use search queries used at the previous iterations.\n",
    "\n",
    "Don't repeat previously performed actions.\n",
    "\n",
    "Don't perform more than {max_iterations} iterations for a given student question.\n",
    "The current iteration number: {iteration_number}. If we exceed the allowed number \n",
    "of iterations, give the best possible answer with the provided information.\n",
    "\n",
    "Output templates:\n",
    "\n",
    "If you want to perform search, use this template:\n",
    "\n",
    "{{\n",
    "\"action\": \"SEARCH\",\n",
    "\"reasoning\": \"<add your reasoning here>\",\n",
    "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
    "}}\n",
    "\n",
    "If you can answer the QUESTION using CONTEXT, use this template:\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER_CONTEXT\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"CONTEXT\"\n",
    "}}\n",
    "\n",
    "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"OWN_KNOWLEDGE\"\n",
    "}}\n",
    "\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<SEARCH_QUERIES>\n",
    "{search_queries}\n",
    "</SEARCH_QUERIES>\n",
    "\n",
    "<CONTEXT> \n",
    "{context}\n",
    "</CONTEXT>\n",
    "\n",
    "<PREVIOUS_ACTIONS>\n",
    "{previous_actions}\n",
    "</PREVIOUS_ACTIONS>\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d0f0cb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 1. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "how do I join the course?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "\n",
      "</PREVIOUS_ACTIONS>\n"
     ]
    }
   ],
   "source": [
    "question = \"how do I join the course?\"\n",
    "\n",
    "search_queries = []\n",
    "search_results = []\n",
    "previous_actions = []\n",
    "context = build_context(search_results)\n",
    "\n",
    "prompt = prompt_template.format(\n",
    "    question=question,\n",
    "    context=context,\n",
    "    search_queries=\"\\n\".join(search_queries),\n",
    "    previous_actions='\\n'.join([json.dumps(a) for a in previous_actions]),\n",
    "    max_iterations=3,\n",
    "    iteration_number=1\n",
    ")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "327cd24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"action\": \"SEARCH\",\n",
      "  \"reasoning\": \"To provide accurate information on how to join the course, I will search for any specific instructions, requirements, or links related to enrollment in the FAQ database.\",\n",
      "  \"keywords\": [\n",
      "    \"how to join the course\",\n",
      "    \"course enrollment\",\n",
      "    \"registration process\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "answer_json = llm(prompt)\n",
    "answer = json.loads(answer_json)\n",
    "print(json.dumps(answer, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a949157f",
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_actions.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5390fd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = answer['keywords']\n",
    "search_queries.extend(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c11ba5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in keywords:\n",
    "    res = search(k)\n",
    "    search_results.extend(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e93323dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Can I still join the course after the start date?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 2},\n",
       " {'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - When will the course start?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 0},\n",
       " {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Can I follow the course after it finishes?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 7},\n",
       " {'text': \"No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Certificate - Can I follow the course in a self-paced mode and get a certificate?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 11},\n",
       " {'text': 'After you create a GitHub account, you should clone the course repo to your local machine using the process outlined in this video: Git for Everybody: How to Clone a Repository from GitHub\\nHaving this local repository on your computer will make it easy for you to access the instructors’ code and make pull requests (if you want to add your own notes or make changes to the course content).\\nYou will probably also create your own repositories that host your notes, versions of your file, to do this. Here is a great tutorial that shows you how to do this: https://www.atlassian.com/git/tutorials/setting-up-a-repository\\nRemember to ignore large database, .csv, and .gz files, and other files that should not be saved to a repository. Use .gitignore for this: https://www.atlassian.com/git/tutorials/saving-changes/gitignore NEVER store passwords or keys in a git repo (even if that repo is set to private).\\nThis is also a great resource: https://dangitgit.com/',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'How do I use Git / GitHub for this course?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 41},\n",
       " {'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - When will the course start?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 0},\n",
       " {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Can I follow the course after it finishes?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 7},\n",
       " {'text': \"No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Certificate - Can I follow the course in a self-paced mode and get a certificate?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 11},\n",
       " {'text': 'Yes, this applies if you want to use Airflow or Prefect instead of Mage, AWS or Snowflake instead of GCP products or Tableau instead of Metabase or Google data studio.\\nThe course covers 2 alternative data stacks, one using GCP and one using local installation of everything. You can use one of them or use your tool of choice.\\nShould you consider it instead of the one tool you use? That we can’t support you if you choose to use a different stack, also you would need to explain the different choices of tool for the peer review of your capstone project.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Is it possible to use tool “X” instead of the one tool you use in the course?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 33},\n",
       " {'text': 'After you create a GitHub account, you should clone the course repo to your local machine using the process outlined in this video: Git for Everybody: How to Clone a Repository from GitHub\\nHaving this local repository on your computer will make it easy for you to access the instructors’ code and make pull requests (if you want to add your own notes or make changes to the course content).\\nYou will probably also create your own repositories that host your notes, versions of your file, to do this. Here is a great tutorial that shows you how to do this: https://www.atlassian.com/git/tutorials/setting-up-a-repository\\nRemember to ignore large database, .csv, and .gz files, and other files that should not be saved to a repository. Use .gitignore for this: https://www.atlassian.com/git/tutorials/saving-changes/gitignore NEVER store passwords or keys in a git repo (even if that repo is set to private).\\nThis is also a great resource: https://dangitgit.com/',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'How do I use Git / GitHub for this course?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 41},\n",
       " {'text': 'After installing all including pyspark (and it is successfully imported), but then running this script on the jupyter notebook\\nimport pyspark\\nfrom pyspark.sql import SparkSession\\nspark = SparkSession.builder \\\\\\n.master(\"local[*]\") \\\\\\n.appName(\\'test\\') \\\\\\n.getOrCreate()\\ndf = spark.read \\\\\\n.option(\"header\", \"true\") \\\\\\n.csv(\\'taxi+_zone_lookup.csv\\')\\ndf.show()\\nit gives the error:\\nRuntimeError: Java gateway process exited before sending its port number\\n✅The solution (for me) was:\\npip install findspark on the command line and then\\nAdd\\nimport findspark\\nfindspark.init()\\nto the top of the script.\\nAnother possible solution is:\\nCheck that pyspark is pointing to the correct location.\\nRun pyspark.__file__. It should be list /home/<your user name>/spark/spark-3.0.3-bin-hadoop3.2/python/pyspark/__init__.py if you followed the videos.\\nIf it is pointing to your python site-packages remove the pyspark directory there and check that you have added the correct exports to you .bashrc file and that there are not any other exports which might supersede the ones provided in the course content.\\nTo add to the solution above, if the errors persist in regards to setting the correct path for spark,  an alternative solution for permanent path setting solve the error is  to set environment variables on system and user environment variables following this tutorial: Install Apache PySpark on Windows PC | Apache Spark Installation Guide\\nOnce everything is installed, skip to 7:14 to set up environment variables. This allows for the environment variables to be set permanently.',\n",
       "  'section': 'Module 5: pyspark',\n",
       "  'question': 'lsRuntimeError: Java gateway process exited before sending its port number',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 321},\n",
       " {'text': 'pd.read_csv\\ndf_iter = pd.read_csv(dataset_url, iterator=True, chunksize=100000)\\nThe data needs to be appended to the parquet file using the fastparquet engine\\ndf.to_parquet(path, compression=\"gzip\", engine=\\'fastparquet\\', append=True)',\n",
       "  'section': 'Module 2: Workflow Orchestration',\n",
       "  'question': 'Process to download the VSC using Pandas is killed right away',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 178},\n",
       " {'text': \"You don't need it. You're accepted. You can also just start learning and submitting homework without registering. It is not checked against any registered list. Registration is just to gauge interest before the start date.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - I have registered for the Data Engineering Bootcamp. When can I expect to receive the confirmation email?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 3},\n",
       " {'text': 'After you create a GitHub account, you should clone the course repo to your local machine using the process outlined in this video: Git for Everybody: How to Clone a Repository from GitHub\\nHaving this local repository on your computer will make it easy for you to access the instructors’ code and make pull requests (if you want to add your own notes or make changes to the course content).\\nYou will probably also create your own repositories that host your notes, versions of your file, to do this. Here is a great tutorial that shows you how to do this: https://www.atlassian.com/git/tutorials/setting-up-a-repository\\nRemember to ignore large database, .csv, and .gz files, and other files that should not be saved to a repository. Use .gitignore for this: https://www.atlassian.com/git/tutorials/saving-changes/gitignore NEVER store passwords or keys in a git repo (even if that repo is set to private).\\nThis is also a great resource: https://dangitgit.com/',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'How do I use Git / GitHub for this course?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 41},\n",
       " {'text': \"If you get the following error\\nYou have to edit variables.tf on the gcp folder, set your project-id and region and zones properly. Then, run terraform apply again.\\nYou can find correct regions/zones here: https://cloud.google.com/compute/docs/regions-zones\\nDeploying MAGE to GCP  with Terraform via the VM (2.2.7)\\nFYI - It can take up to 20 minutes to deploy the MAGE Terraform files if you are using a GCP Virtual Machine. It is normal, so don’t interrupt the process or think it’s taking too long. If you have, make sure you run a terraform destroy before trying again as you will have likely partially created resources which will cause errors next time you run `terraform apply`.\\n`terraform destroy` may not completely delete partial resources - go to Google Cloud Console and use the search bar at the top to search for the ‘app.name’ you declared in your variables.tf file; this will list all resources with that name - make sure you delete them all before running `terraform apply` again.\\nWhy are my GCP free credits going so fast? MAGE .tf files - Terraform Destroy not destroying all Resources\\nI checked my GCP billing last night & the MAGE Terraform IaC didn't destroy a GCP Resource called Filestore as ‘mage-data-prep- it has been costing £5.01 of my free credits each day  I now have £151 left - Alexey has assured me that This amount WILL BE SUFFICIENT funds to finish the course. Note to anyone who had issues deploying the MAGE terraform code: check your billing account to see what you're being charged for (main menu - billing) (even if it's your free credits) and run a search for 'mage-data-prep' in the top bar just to be sure that your resources have been destroyed - if any come up delete them.\",\n",
       "  'section': 'Module 2: Workflow Orchestration',\n",
       "  'question': 'GCP - 2.2.7d Part 2 - Getting error when you run terraform apply',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 174}]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d9768c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dedup(seq):\n",
    "    seen = set()\n",
    "    result = []\n",
    "    for el in seq:\n",
    "        _id = el['_id']\n",
    "        if _id in seen:\n",
    "            continue\n",
    "        seen.add(_id)\n",
    "        result.append(el)\n",
    "    return result\n",
    "\n",
    "search_results = dedup(search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2563cfb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 2. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "how do I join the course?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "how to join the course\n",
      "course enrollment\n",
      "registration process\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "section: General course-related questions\n",
      "question: Course - Can I still join the course after the start date?\n",
      "answer: Yes, even if you don't register, you're still eligible to submit the homeworks.\n",
      "Be aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - When will the course start?\n",
      "answer: The purpose of this document is to capture frequently asked technical questions\n",
      "The exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\n",
      "Subscribe to course public Google Calendar (it works from Desktop only).\n",
      "Register before the course starts using this link.\n",
      "Join the course Telegram channel with announcements.\n",
      "Don’t forget to register in DataTalks.Club's Slack and join the channel.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - Can I follow the course after it finishes?\n",
      "answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\n",
      "You can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Certificate - Can I follow the course in a self-paced mode and get a certificate?\n",
      "answer: No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\n",
      "\n",
      "section: General course-related questions\n",
      "question: How do I use Git / GitHub for this course?\n",
      "answer: After you create a GitHub account, you should clone the course repo to your local machine using the process outlined in this video: Git for Everybody: How to Clone a Repository from GitHub\n",
      "Having this local repository on your computer will make it easy for you to access the instructors’ code and make pull requests (if you want to add your own notes or make changes to the course content).\n",
      "You will probably also create your own repositories that host your notes, versions of your file, to do this. Here is a great tutorial that shows you how to do this: https://www.atlassian.com/git/tutorials/setting-up-a-repository\n",
      "Remember to ignore large database, .csv, and .gz files, and other files that should not be saved to a repository. Use .gitignore for this: https://www.atlassian.com/git/tutorials/saving-changes/gitignore NEVER store passwords or keys in a git repo (even if that repo is set to private).\n",
      "This is also a great resource: https://dangitgit.com/\n",
      "\n",
      "section: General course-related questions\n",
      "question: Is it possible to use tool “X” instead of the one tool you use in the course?\n",
      "answer: Yes, this applies if you want to use Airflow or Prefect instead of Mage, AWS or Snowflake instead of GCP products or Tableau instead of Metabase or Google data studio.\n",
      "The course covers 2 alternative data stacks, one using GCP and one using local installation of everything. You can use one of them or use your tool of choice.\n",
      "Should you consider it instead of the one tool you use? That we can’t support you if you choose to use a different stack, also you would need to explain the different choices of tool for the peer review of your capstone project.\n",
      "\n",
      "section: Module 5: pyspark\n",
      "question: lsRuntimeError: Java gateway process exited before sending its port number\n",
      "answer: After installing all including pyspark (and it is successfully imported), but then running this script on the jupyter notebook\n",
      "import pyspark\n",
      "from pyspark.sql import SparkSession\n",
      "spark = SparkSession.builder \\\n",
      ".master(\"local[*]\") \\\n",
      ".appName('test') \\\n",
      ".getOrCreate()\n",
      "df = spark.read \\\n",
      ".option(\"header\", \"true\") \\\n",
      ".csv('taxi+_zone_lookup.csv')\n",
      "df.show()\n",
      "it gives the error:\n",
      "RuntimeError: Java gateway process exited before sending its port number\n",
      "✅The solution (for me) was:\n",
      "pip install findspark on the command line and then\n",
      "Add\n",
      "import findspark\n",
      "findspark.init()\n",
      "to the top of the script.\n",
      "Another possible solution is:\n",
      "Check that pyspark is pointing to the correct location.\n",
      "Run pyspark.__file__. It should be list /home/<your user name>/spark/spark-3.0.3-bin-hadoop3.2/python/pyspark/__init__.py if you followed the videos.\n",
      "If it is pointing to your python site-packages remove the pyspark directory there and check that you have added the correct exports to you .bashrc file and that there are not any other exports which might supersede the ones provided in the course content.\n",
      "To add to the solution above, if the errors persist in regards to setting the correct path for spark,  an alternative solution for permanent path setting solve the error is  to set environment variables on system and user environment variables following this tutorial: Install Apache PySpark on Windows PC | Apache Spark Installation Guide\n",
      "Once everything is installed, skip to 7:14 to set up environment variables. This allows for the environment variables to be set permanently.\n",
      "\n",
      "section: Module 2: Workflow Orchestration\n",
      "question: Process to download the VSC using Pandas is killed right away\n",
      "answer: pd.read_csv\n",
      "df_iter = pd.read_csv(dataset_url, iterator=True, chunksize=100000)\n",
      "The data needs to be appended to the parquet file using the fastparquet engine\n",
      "df.to_parquet(path, compression=\"gzip\", engine='fastparquet', append=True)\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - I have registered for the Data Engineering Bootcamp. When can I expect to receive the confirmation email?\n",
      "answer: You don't need it. You're accepted. You can also just start learning and submitting homework without registering. It is not checked against any registered list. Registration is just to gauge interest before the start date.\n",
      "\n",
      "section: Module 2: Workflow Orchestration\n",
      "question: GCP - 2.2.7d Part 2 - Getting error when you run terraform apply\n",
      "answer: If you get the following error\n",
      "You have to edit variables.tf on the gcp folder, set your project-id and region and zones properly. Then, run terraform apply again.\n",
      "You can find correct regions/zones here: https://cloud.google.com/compute/docs/regions-zones\n",
      "Deploying MAGE to GCP  with Terraform via the VM (2.2.7)\n",
      "FYI - It can take up to 20 minutes to deploy the MAGE Terraform files if you are using a GCP Virtual Machine. It is normal, so don’t interrupt the process or think it’s taking too long. If you have, make sure you run a terraform destroy before trying again as you will have likely partially created resources which will cause errors next time you run `terraform apply`.\n",
      "`terraform destroy` may not completely delete partial resources - go to Google Cloud Console and use the search bar at the top to search for the ‘app.name’ you declared in your variables.tf file; this will list all resources with that name - make sure you delete them all before running `terraform apply` again.\n",
      "Why are my GCP free credits going so fast? MAGE .tf files - Terraform Destroy not destroying all Resources\n",
      "I checked my GCP billing last night & the MAGE Terraform IaC didn't destroy a GCP Resource called Filestore as ‘mage-data-prep- it has been costing £5.01 of my free credits each day  I now have £151 left - Alexey has assured me that This amount WILL BE SUFFICIENT funds to finish the course. Note to anyone who had issues deploying the MAGE terraform code: check your billing account to see what you're being charged for (main menu - billing) (even if it's your free credits) and run a search for 'mage-data-prep' in the top bar just to be sure that your resources have been destroyed - if any come up delete them.\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"To provide accurate information on how to join the course, I will search for any specific instructions, requirements, or links related to enrollment in the FAQ database.\", \"keywords\": [\"how to join the course\", \"course enrollment\", \"registration process\"]}\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"ANSWER_CONTEXT\",\n",
      "  \"answer\": \"To join the course, you need to register before the course starts using the provided link. The course begins on January 15, 2024, at 17h00, and it's important to subscribe to the course public Google Calendar to stay updated. You should also join the course's Telegram channel for announcements and register on DataTalks.Club's Slack to participate in the community.\",\n",
      "  \"source\": \"CONTEXT\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# question = \"how do I join the course?\"\n",
    "\n",
    "# search_queries = []\n",
    "# search_results = []\n",
    "# previous_actions = []\n",
    "\n",
    "context = build_context(search_results)\n",
    "\n",
    "prompt = prompt_template.format(\n",
    "    question=question,\n",
    "    context=context,\n",
    "    search_queries=\"\\n\".join(search_queries),\n",
    "    previous_actions='\\n'.join([json.dumps(a) for a in previous_actions]),\n",
    "    max_iterations=3,\n",
    "    iteration_number=2\n",
    ")\n",
    "print(prompt)\n",
    "\n",
    "answer_json = llm(prompt)\n",
    "answer = json.loads(answer_json)\n",
    "print(json.dumps(answer, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e4938b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION #0...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 0. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "what do I need to do to be successful at module 1?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"SEARCH\",\n",
      "  \"reasoning\": \"To provide a comprehensive answer about success in module 1, I need to gather information regarding expectations, recommended practices, and key resources from the FAQ database.\",\n",
      "  \"keywords\": [\n",
      "    \"successful strategies module 1\",\n",
      "    \"module 1 tips\",\n",
      "    \"module 1 expectations\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "ITERATION #1...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 1. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "what do I need to do to be successful at module 1?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "successful strategies module 1\n",
      "module 1 tips\n",
      "module 1 expectations\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "section: Module 5: pyspark\n",
      "question: Module Not Found Error in Jupyter Notebook .\n",
      "answer: Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\n",
      "The solution which worked for me(use following in jupyter notebook) :\n",
      "!pip install findspark\n",
      "import findspark\n",
      "findspark.init()\n",
      "Thereafter , import pyspark and create spark contex<<t as usual\n",
      "None of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\n",
      "Filter based on conditions based on multiple columns\n",
      "from pyspark.sql.functions import col\n",
      "new_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\n",
      "Krishna Anand\n",
      "\n",
      "section: Module 5: pyspark\n",
      "question: Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\n",
      "answer: You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\n",
      "` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\n",
      "export PYTHONPATH=”${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}”\n",
      "Make sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\n",
      "For instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\n",
      "Then the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\n",
      "Additionally, you can check for the version of ‘py4j’ of the spark you’re using from here and update as mentioned above.\n",
      "~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Postgres - ModuleNotFoundError: No module named 'psycopg2'\n",
      "answer: Issue:\n",
      "e…\n",
      "Solution:\n",
      "pip install psycopg2-binary\n",
      "If you already have it, you might need to update it:\n",
      "pip install psycopg2-binary --upgrade\n",
      "Other methods, if the above fails:\n",
      "if you are getting the “ ModuleNotFoundError: No module named 'psycopg2' “ error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\n",
      "First uninstall the psycopg package\n",
      "Then update conda or pip\n",
      "Then install psycopg again using pip.\n",
      "if you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\n",
      "\n",
      "section: Module 4: analytics engineering with dbt\n",
      "question: DBT - Error: No module named 'pytz' while setting up dbt with docker\n",
      "answer: Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\n",
      "Solution:\n",
      "Add `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLALchemy - TypeError 'module' object is not callable\n",
      "answer: create_engine('postgresql://root:root@localhost:5432/ny_taxi')  I get the error \"TypeError: 'module' object is not callable\"\n",
      "Solution:\n",
      "conn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\n",
      "engine = create_engine(conn_string)\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"To provide a comprehensive answer about success in module 1, I need to gather information regarding expectations, recommended practices, and key resources from the FAQ database.\", \"keywords\": [\"successful strategies module 1\", \"module 1 tips\", \"module 1 expectations\"]}\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"SEARCH\",\n",
      "  \"reasoning\": \"To find specific strategies and tips that could help students succeed in Module 1, I will search for documents that may contain advice or best practices relevant to the module on Docker and Terraform.\",\n",
      "  \"keywords\": [\n",
      "    \"tips for success Module 1\",\n",
      "    \"Module 1 study strategies\",\n",
      "    \"Module 1 recommendations\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "ITERATION #2...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 2. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "what do I need to do to be successful at module 1?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "successful strategies module 1\n",
      "module 1 expectations\n",
      "Module 1 study strategies\n",
      "Module 1 recommendations\n",
      "module 1 tips\n",
      "tips for success Module 1\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "section: Module 5: pyspark\n",
      "question: Module Not Found Error in Jupyter Notebook .\n",
      "answer: Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\n",
      "The solution which worked for me(use following in jupyter notebook) :\n",
      "!pip install findspark\n",
      "import findspark\n",
      "findspark.init()\n",
      "Thereafter , import pyspark and create spark contex<<t as usual\n",
      "None of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\n",
      "Filter based on conditions based on multiple columns\n",
      "from pyspark.sql.functions import col\n",
      "new_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\n",
      "Krishna Anand\n",
      "\n",
      "section: Module 5: pyspark\n",
      "question: Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\n",
      "answer: You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\n",
      "` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\n",
      "export PYTHONPATH=”${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}”\n",
      "Make sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\n",
      "For instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\n",
      "Then the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\n",
      "Additionally, you can check for the version of ‘py4j’ of the spark you’re using from here and update as mentioned above.\n",
      "~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Postgres - ModuleNotFoundError: No module named 'psycopg2'\n",
      "answer: Issue:\n",
      "e…\n",
      "Solution:\n",
      "pip install psycopg2-binary\n",
      "If you already have it, you might need to update it:\n",
      "pip install psycopg2-binary --upgrade\n",
      "Other methods, if the above fails:\n",
      "if you are getting the “ ModuleNotFoundError: No module named 'psycopg2' “ error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\n",
      "First uninstall the psycopg package\n",
      "Then update conda or pip\n",
      "Then install psycopg again using pip.\n",
      "if you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\n",
      "\n",
      "section: Module 4: analytics engineering with dbt\n",
      "question: DBT - Error: No module named 'pytz' while setting up dbt with docker\n",
      "answer: Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\n",
      "Solution:\n",
      "Add `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLALchemy - TypeError 'module' object is not callable\n",
      "answer: create_engine('postgresql://root:root@localhost:5432/ny_taxi')  I get the error \"TypeError: 'module' object is not callable\"\n",
      "Solution:\n",
      "conn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\n",
      "engine = create_engine(conn_string)\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"To provide a comprehensive answer about success in module 1, I need to gather information regarding expectations, recommended practices, and key resources from the FAQ database.\", \"keywords\": [\"successful strategies module 1\", \"module 1 tips\", \"module 1 expectations\"]}\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"To find specific strategies and tips that could help students succeed in Module 1, I will search for documents that may contain advice or best practices relevant to the module on Docker and Terraform.\", \"keywords\": [\"tips for success Module 1\", \"Module 1 study strategies\", \"Module 1 recommendations\"]}\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"SEARCH\",\n",
      "  \"reasoning\": \"To further understand how to be successful in Module 1, I'll look for more specific documents or recommendations related to studying for Docker and Terraform or any best practices that could enhance readiness for this module.\",\n",
      "  \"keywords\": [\n",
      "    \"Module 1 best practices\",\n",
      "    \"Docker and Terraform study tips\",\n",
      "    \"how to excel in Module 1\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "ITERATION #3...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 3. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "what do I need to do to be successful at module 1?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "how to excel in Module 1\n",
      "successful strategies module 1\n",
      "module 1 expectations\n",
      "Docker and Terraform study tips\n",
      "Module 1 best practices\n",
      "Module 1 study strategies\n",
      "Module 1 recommendations\n",
      "module 1 tips\n",
      "tips for success Module 1\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "section: Module 5: pyspark\n",
      "question: Module Not Found Error in Jupyter Notebook .\n",
      "answer: Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\n",
      "The solution which worked for me(use following in jupyter notebook) :\n",
      "!pip install findspark\n",
      "import findspark\n",
      "findspark.init()\n",
      "Thereafter , import pyspark and create spark contex<<t as usual\n",
      "None of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\n",
      "Filter based on conditions based on multiple columns\n",
      "from pyspark.sql.functions import col\n",
      "new_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\n",
      "Krishna Anand\n",
      "\n",
      "section: Module 5: pyspark\n",
      "question: Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\n",
      "answer: You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\n",
      "` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\n",
      "export PYTHONPATH=”${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}”\n",
      "Make sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\n",
      "For instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\n",
      "Then the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\n",
      "Additionally, you can check for the version of ‘py4j’ of the spark you’re using from here and update as mentioned above.\n",
      "~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Postgres - ModuleNotFoundError: No module named 'psycopg2'\n",
      "answer: Issue:\n",
      "e…\n",
      "Solution:\n",
      "pip install psycopg2-binary\n",
      "If you already have it, you might need to update it:\n",
      "pip install psycopg2-binary --upgrade\n",
      "Other methods, if the above fails:\n",
      "if you are getting the “ ModuleNotFoundError: No module named 'psycopg2' “ error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\n",
      "First uninstall the psycopg package\n",
      "Then update conda or pip\n",
      "Then install psycopg again using pip.\n",
      "if you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\n",
      "\n",
      "section: Module 4: analytics engineering with dbt\n",
      "question: DBT - Error: No module named 'pytz' while setting up dbt with docker\n",
      "answer: Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\n",
      "Solution:\n",
      "Add `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLALchemy - TypeError 'module' object is not callable\n",
      "answer: create_engine('postgresql://root:root@localhost:5432/ny_taxi')  I get the error \"TypeError: 'module' object is not callable\"\n",
      "Solution:\n",
      "conn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\n",
      "engine = create_engine(conn_string)\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Docker - cs to store all code in your default Linux distro to get the best out of file system performance (since Docker runs on WSL2 backend by default for Windows 10 Home / Windows 11 Home users).\n",
      "answer: More info in the Docker Docs on Best Practises\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLAlchemy - ModuleNotFoundError: No module named 'psycopg2'.\n",
      "answer: Error raised during the jupyter notebook’s cell execution:\n",
      "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi').\n",
      "Solution: Need to install Python module “psycopg2”. Can be installed by Conda or pip.\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Terraform - Error: Failed to query available provider packages │ Could not retrieve the list of available versions for provider hashicorp/google: could not query │ provider registry for registry.terrafogorm.io/hashicorp/google: the request failed after 2 attempts, │ please try again later\n",
      "answer: It is an internet connectivity error, terraform is somehow not able to access the online registry. Check your VPN/Firewall settings (or just clear cookies or restart your network). Try terraform init again after this, it should work.\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Terraform - Error acquiring the state lock\n",
      "answer: https://github.com/hashicorp/terraform/issues/14513\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Terraform - Where can I find the Terraform 1.1.3 Linux (AMD 64)?\n",
      "answer: Here: https://releases.hashicorp.com/terraform/1.1.3/terraform_1.1.3_linux_amd64.zip\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Terraform - Terraform initialized in an empty directory! The directory has no Terraform configuration files. You may begin working with Terraform immediately by creating Terraform configuration files.g\n",
      "answer: You get this error because I run the command terraform init outside the working directory, and this is wrong.You need first to navigate to the working directory that contains terraform configuration files, and and then run the command.\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Terraform - Error 400 Bad Request.  Invalid JWT Token  on WSL.\n",
      "answer: When running\n",
      "terraform apply\n",
      "on wsl2 I've got this error:\n",
      "│ Error: Post \"https://storage.googleapis.com/storage/v1/b?alt=json&prettyPrint=false&project=<your-project-id>\": oauth2: cannot fetch token: 400 Bad Request\n",
      "│ Response: {\"error\":\"invalid_grant\",\"error_description\":\"Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.\"}\n",
      "IT happens because there may be time desync on your machine which affects computing JWT\n",
      "To fix this, run the command\n",
      "sudo hwclock -s\n",
      "which fixes your system time.\n",
      "Reference\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"To provide a comprehensive answer about success in module 1, I need to gather information regarding expectations, recommended practices, and key resources from the FAQ database.\", \"keywords\": [\"successful strategies module 1\", \"module 1 tips\", \"module 1 expectations\"]}\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"To find specific strategies and tips that could help students succeed in Module 1, I will search for documents that may contain advice or best practices relevant to the module on Docker and Terraform.\", \"keywords\": [\"tips for success Module 1\", \"Module 1 study strategies\", \"Module 1 recommendations\"]}\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"To further understand how to be successful in Module 1, I'll look for more specific documents or recommendations related to studying for Docker and Terraform or any best practices that could enhance readiness for this module.\", \"keywords\": [\"Module 1 best practices\", \"Docker and Terraform study tips\", \"how to excel in Module 1\"]}\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"ANSWER\",\n",
      "  \"answer\": \"To be successful in Module 1 (Docker and Terraform), focus on a few key strategies: 1. Understand the basics of Docker and Terraform, including their respective commands and usage. 2. Take advantage of resources like the official documentation and community forums for troubleshooting and best practices. 3. Work on practical projects to apply what you've learned and reinforce your understanding. 4. Stay organized and keep your development environment clean to avoid errors related to dependencies. Finally, collaboration with peers can provide additional insights and support.\",\n",
      "  \"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "question = \"what do I need to do to be successful at module 1?\"\n",
    "\n",
    "search_queries = []\n",
    "search_results = []\n",
    "previous_actions = []\n",
    "\n",
    "\n",
    "iteration = 0\n",
    "\n",
    "while True:\n",
    "    print(f'ITERATION #{iteration}...')\n",
    "\n",
    "    context = build_context(search_results)\n",
    "    prompt = prompt_template.format(\n",
    "        question=question,\n",
    "        context=context,\n",
    "        search_queries=\"\\n\".join(search_queries),\n",
    "        previous_actions='\\n'.join([json.dumps(a) for a in previous_actions]),\n",
    "        max_iterations=3,\n",
    "        iteration_number=iteration\n",
    "    )\n",
    "\n",
    "    print(prompt)\n",
    "\n",
    "    answer_json = llm(prompt)\n",
    "    answer = json.loads(answer_json)\n",
    "    print(json.dumps(answer, indent=2))\n",
    "\n",
    "    previous_actions.append(answer)\n",
    "\n",
    "    action = answer['action']\n",
    "    if action != 'SEARCH':\n",
    "        break\n",
    "\n",
    "    keywords = answer['keywords']\n",
    "    search_queries = list(set(search_queries) | set(keywords))\n",
    "    \n",
    "    for k in keywords:\n",
    "        res = search(k)\n",
    "        search_results.extend(res)\n",
    "\n",
    "    search_results = dedup(search_results)\n",
    "    \n",
    "    iteration = iteration + 1\n",
    "    if iteration >= 4:\n",
    "        break\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cf4c2755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agentic_search(question):\n",
    "    search_queries = []\n",
    "    search_results = []\n",
    "    previous_actions = []\n",
    "\n",
    "    iteration = 0\n",
    "    \n",
    "    while True:\n",
    "        print(f'ITERATION #{iteration}...')\n",
    "    \n",
    "        context = build_context(search_results)\n",
    "        prompt = prompt_template.format(\n",
    "            question=question,\n",
    "            context=context,\n",
    "            search_queries=\"\\n\".join(search_queries),\n",
    "            previous_actions='\\n'.join([json.dumps(a) for a in previous_actions]),\n",
    "            max_iterations=3,\n",
    "            iteration_number=iteration\n",
    "        )\n",
    "    \n",
    "        print(prompt)\n",
    "    \n",
    "        answer_json = llm(prompt)\n",
    "        answer = json.loads(answer_json)\n",
    "        print(json.dumps(answer, indent=2))\n",
    "\n",
    "        previous_actions.append(answer)\n",
    "    \n",
    "        action = answer['action']\n",
    "        if action != 'SEARCH':\n",
    "            break\n",
    "    \n",
    "        keywords = answer['keywords']\n",
    "        search_queries = list(set(search_queries) | set(keywords))\n",
    "\n",
    "        for k in keywords:\n",
    "            res = search(k)\n",
    "            search_results.extend(res)\n",
    "    \n",
    "        search_results = dedup(search_results)\n",
    "        \n",
    "        iteration = iteration + 1\n",
    "        if iteration >= 4:\n",
    "            break\n",
    "    \n",
    "        print()\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "afbe4807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION #0...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 0. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "how do I prepare for the course?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"SEARCH\",\n",
      "  \"reasoning\": \"I need to gather specific information on how to prepare for the course, as there is currently no context available about preparation steps or guidelines.\",\n",
      "  \"keywords\": [\n",
      "    \"course preparation\",\n",
      "    \"how to prepare for course\",\n",
      "    \"course readiness tips\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "ITERATION #1...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 1. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "how do I prepare for the course?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "how to prepare for course\n",
      "course preparation\n",
      "course readiness tips\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "section: General course-related questions\n",
      "question: Course - When will the course start?\n",
      "answer: The purpose of this document is to capture frequently asked technical questions\n",
      "The exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\n",
      "Subscribe to course public Google Calendar (it works from Desktop only).\n",
      "Register before the course starts using this link.\n",
      "Join the course Telegram channel with announcements.\n",
      "Don’t forget to register in DataTalks.Club's Slack and join the channel.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - Can I follow the course after it finishes?\n",
      "answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\n",
      "You can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Certificate - Can I follow the course in a self-paced mode and get a certificate?\n",
      "answer: No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Is it possible to use tool “X” instead of the one tool you use in the course?\n",
      "answer: Yes, this applies if you want to use Airflow or Prefect instead of Mage, AWS or Snowflake instead of GCP products or Tableau instead of Metabase or Google data studio.\n",
      "The course covers 2 alternative data stacks, one using GCP and one using local installation of everything. You can use one of them or use your tool of choice.\n",
      "Should you consider it instead of the one tool you use? That we can’t support you if you choose to use a different stack, also you would need to explain the different choices of tool for the peer review of your capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: How do I use Git / GitHub for this course?\n",
      "answer: After you create a GitHub account, you should clone the course repo to your local machine using the process outlined in this video: Git for Everybody: How to Clone a Repository from GitHub\n",
      "Having this local repository on your computer will make it easy for you to access the instructors’ code and make pull requests (if you want to add your own notes or make changes to the course content).\n",
      "You will probably also create your own repositories that host your notes, versions of your file, to do this. Here is a great tutorial that shows you how to do this: https://www.atlassian.com/git/tutorials/setting-up-a-repository\n",
      "Remember to ignore large database, .csv, and .gz files, and other files that should not be saved to a repository. Use .gitignore for this: https://www.atlassian.com/git/tutorials/saving-changes/gitignore NEVER store passwords or keys in a git repo (even if that repo is set to private).\n",
      "This is also a great resource: https://dangitgit.com/\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"I need to gather specific information on how to prepare for the course, as there is currently no context available about preparation steps or guidelines.\", \"keywords\": [\"course preparation\", \"how to prepare for course\", \"course readiness tips\"]}\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"SEARCH\",\n",
      "  \"reasoning\": \"The current context does not contain any information specific to preparing for the course. I will search for detailed guidelines or tips on how to prepare effectively for the upcoming course.\",\n",
      "  \"keywords\": [\n",
      "    \"course preparation tips\",\n",
      "    \"how to prepare for a course\",\n",
      "    \"preparing for coursework\",\n",
      "    \"course readiness strategies\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "ITERATION #2...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 2. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "how do I prepare for the course?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "course readiness strategies\n",
      "preparing for coursework\n",
      "how to prepare for course\n",
      "course preparation tips\n",
      "how to prepare for a course\n",
      "course readiness tips\n",
      "course preparation\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "section: General course-related questions\n",
      "question: Course - When will the course start?\n",
      "answer: The purpose of this document is to capture frequently asked technical questions\n",
      "The exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\n",
      "Subscribe to course public Google Calendar (it works from Desktop only).\n",
      "Register before the course starts using this link.\n",
      "Join the course Telegram channel with announcements.\n",
      "Don’t forget to register in DataTalks.Club's Slack and join the channel.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - Can I follow the course after it finishes?\n",
      "answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\n",
      "You can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Certificate - Can I follow the course in a self-paced mode and get a certificate?\n",
      "answer: No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Is it possible to use tool “X” instead of the one tool you use in the course?\n",
      "answer: Yes, this applies if you want to use Airflow or Prefect instead of Mage, AWS or Snowflake instead of GCP products or Tableau instead of Metabase or Google data studio.\n",
      "The course covers 2 alternative data stacks, one using GCP and one using local installation of everything. You can use one of them or use your tool of choice.\n",
      "Should you consider it instead of the one tool you use? That we can’t support you if you choose to use a different stack, also you would need to explain the different choices of tool for the peer review of your capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: How do I use Git / GitHub for this course?\n",
      "answer: After you create a GitHub account, you should clone the course repo to your local machine using the process outlined in this video: Git for Everybody: How to Clone a Repository from GitHub\n",
      "Having this local repository on your computer will make it easy for you to access the instructors’ code and make pull requests (if you want to add your own notes or make changes to the course content).\n",
      "You will probably also create your own repositories that host your notes, versions of your file, to do this. Here is a great tutorial that shows you how to do this: https://www.atlassian.com/git/tutorials/setting-up-a-repository\n",
      "Remember to ignore large database, .csv, and .gz files, and other files that should not be saved to a repository. Use .gitignore for this: https://www.atlassian.com/git/tutorials/saving-changes/gitignore NEVER store passwords or keys in a git repo (even if that repo is set to private).\n",
      "This is also a great resource: https://dangitgit.com/\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"I need to gather specific information on how to prepare for the course, as there is currently no context available about preparation steps or guidelines.\", \"keywords\": [\"course preparation\", \"how to prepare for course\", \"course readiness tips\"]}\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"The current context does not contain any information specific to preparing for the course. I will search for detailed guidelines or tips on how to prepare effectively for the upcoming course.\", \"keywords\": [\"course preparation tips\", \"how to prepare for a course\", \"preparing for coursework\", \"course readiness strategies\"]}\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"SEARCH\",\n",
      "  \"reasoning\": \"The previous searches did not yield specific actionable steps or tips for course preparation. I will perform another search to find more detailed guidance or strategies for getting ready for the course.\",\n",
      "  \"keywords\": [\n",
      "    \"how to gear up for a course\",\n",
      "    \"preparation strategies for coursework\",\n",
      "    \"effective course preparation methods\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "ITERATION #3...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 3. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "how do I prepare for the course?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "course readiness strategies\n",
      "preparing for coursework\n",
      "course preparation tips\n",
      "how to prepare for a course\n",
      "how to gear up for a course\n",
      "preparation strategies for coursework\n",
      "how to prepare for course\n",
      "course readiness tips\n",
      "course preparation\n",
      "effective course preparation methods\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "section: General course-related questions\n",
      "question: Course - When will the course start?\n",
      "answer: The purpose of this document is to capture frequently asked technical questions\n",
      "The exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\n",
      "Subscribe to course public Google Calendar (it works from Desktop only).\n",
      "Register before the course starts using this link.\n",
      "Join the course Telegram channel with announcements.\n",
      "Don’t forget to register in DataTalks.Club's Slack and join the channel.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - Can I follow the course after it finishes?\n",
      "answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\n",
      "You can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Certificate - Can I follow the course in a self-paced mode and get a certificate?\n",
      "answer: No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Is it possible to use tool “X” instead of the one tool you use in the course?\n",
      "answer: Yes, this applies if you want to use Airflow or Prefect instead of Mage, AWS or Snowflake instead of GCP products or Tableau instead of Metabase or Google data studio.\n",
      "The course covers 2 alternative data stacks, one using GCP and one using local installation of everything. You can use one of them or use your tool of choice.\n",
      "Should you consider it instead of the one tool you use? That we can’t support you if you choose to use a different stack, also you would need to explain the different choices of tool for the peer review of your capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: How do I use Git / GitHub for this course?\n",
      "answer: After you create a GitHub account, you should clone the course repo to your local machine using the process outlined in this video: Git for Everybody: How to Clone a Repository from GitHub\n",
      "Having this local repository on your computer will make it easy for you to access the instructors’ code and make pull requests (if you want to add your own notes or make changes to the course content).\n",
      "You will probably also create your own repositories that host your notes, versions of your file, to do this. Here is a great tutorial that shows you how to do this: https://www.atlassian.com/git/tutorials/setting-up-a-repository\n",
      "Remember to ignore large database, .csv, and .gz files, and other files that should not be saved to a repository. Use .gitignore for this: https://www.atlassian.com/git/tutorials/saving-changes/gitignore NEVER store passwords or keys in a git repo (even if that repo is set to private).\n",
      "This is also a great resource: https://dangitgit.com/\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"I need to gather specific information on how to prepare for the course, as there is currently no context available about preparation steps or guidelines.\", \"keywords\": [\"course preparation\", \"how to prepare for course\", \"course readiness tips\"]}\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"The current context does not contain any information specific to preparing for the course. I will search for detailed guidelines or tips on how to prepare effectively for the upcoming course.\", \"keywords\": [\"course preparation tips\", \"how to prepare for a course\", \"preparing for coursework\", \"course readiness strategies\"]}\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"The previous searches did not yield specific actionable steps or tips for course preparation. I will perform another search to find more detailed guidance or strategies for getting ready for the course.\", \"keywords\": [\"how to gear up for a course\", \"preparation strategies for coursework\", \"effective course preparation methods\"]}\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"ANSWER\",\n",
      "  \"answer\": \"To prepare for the course effectively, you should consider the following strategies:\\n1. **Register**: Ensure you are registered for the course before it starts, using the provided registration link.\\n2. **Join Communication Channels**: Subscribe to the course public Google Calendar, join the course Telegram channel for announcements, and register on DataTalks.Club's Slack to stay updated.\\n3. **Familiarize Yourself with Tools**: If you're expected to use specific tools or technologies (like Git or a particular data stack), take the time to learn the basics or review relevant resources.\\n4. **Plan Your Schedule**: Since the course starts on January 15, 2024, at 17h00, allocate specific times in your schedule to attend live sessions and complete coursework. \\n5. **Preparation Material**: Look for any preliminary materials or guidelines that might be offered prior to the start date, so you can come prepared.\\n6. **Review Past Cohort Materials**: If available, examine materials from past cohorts, as these can greatly assist your understanding and preparation for upcoming projects and homework.\\n7. **Set Up Your Development Environment**: Ensure you have all required software and tools set up on your machine ahead of time to avoid technical issues during the course.\\n\\nBy following these preparation steps, you will be better equipped to engage and succeed in the course.\",\n",
      "  \"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'action': 'ANSWER',\n",
       " 'answer': \"To prepare for the course effectively, you should consider the following strategies:\\n1. **Register**: Ensure you are registered for the course before it starts, using the provided registration link.\\n2. **Join Communication Channels**: Subscribe to the course public Google Calendar, join the course Telegram channel for announcements, and register on DataTalks.Club's Slack to stay updated.\\n3. **Familiarize Yourself with Tools**: If you're expected to use specific tools or technologies (like Git or a particular data stack), take the time to learn the basics or review relevant resources.\\n4. **Plan Your Schedule**: Since the course starts on January 15, 2024, at 17h00, allocate specific times in your schedule to attend live sessions and complete coursework. \\n5. **Preparation Material**: Look for any preliminary materials or guidelines that might be offered prior to the start date, so you can come prepared.\\n6. **Review Past Cohort Materials**: If available, examine materials from past cohorts, as these can greatly assist your understanding and preparation for upcoming projects and homework.\\n7. **Set Up Your Development Environment**: Ensure you have all required software and tools set up on your machine ahead of time to avoid technical issues during the course.\\n\\nBy following these preparation steps, you will be better equipped to engage and succeed in the course.\",\n",
       " 'source': 'OWN_KNOWLEDGE'}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agentic_search('how do I prepare for the course?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "58f306b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5,\n",
    "        output_ids=True\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7db04cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"search\",\n",
    "    \"description\": \"Search the FAQ database\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Search query text to look up in the course FAQ.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"query\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f30bc5ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ResponseFunctionToolCall(arguments='{\"query\":\"module 1 tips\"}', call_id='call_QJb4iQ942phHlMYZOvlboXnH', name='search', type='function_call', id='fc_6877e90ebb7c8198850ba6405e1ce5fe01f3f725dd2a3590', status='completed')]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"How do I do well in module 1?\"\n",
    "\n",
    "developer_prompt = \"\"\"\n",
    "You're a course teaching assistant. \n",
    "You're given a question from a course student and your task is to answer it.\n",
    "\"\"\".strip()\n",
    "\n",
    "tools = [search_tool]\n",
    "\n",
    "chat_messages = [\n",
    "    {\"role\": \"developer\", \"content\": developer_prompt},\n",
    "    {\"role\": \"user\", \"content\": question}\n",
    "]\n",
    "\n",
    "response = client.responses.create(\n",
    "    model='gpt-4o-mini',\n",
    "    input=chat_messages,\n",
    "    tools=tools\n",
    ")\n",
    "response.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ad38c462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'module 1 tips'}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calls = response.output\n",
    "call = calls[0]\n",
    "call\n",
    "\n",
    "call_id = call.call_id\n",
    "call_id\n",
    "\n",
    "f_name = call.name\n",
    "f_name\n",
    "\n",
    "arguments = json.loads(call.arguments)\n",
    "arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3a74eb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = globals()[f_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5ab059c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = f(**arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4cb1d404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"text\": \"Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\\nThe solution which worked for me(use following in jupyter notebook) :\\n!pip install findspark\\nimport findspark\\nfindspark.init()\\nThereafter , import pyspark and create spark contex<<t as usual\\nNone of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\\nFilter based on conditions based on multiple columns\\nfrom pyspark.sql.functions import col\\nnew_final.filter((new_final.a_zone==\\\"Murray Hill\\\") & (new_final.b_zone==\\\"Midwood\\\")).show()\\nKrishna Anand\",\n",
      "    \"section\": \"Module 5: pyspark\",\n",
      "    \"question\": \"Module Not Found Error in Jupyter Notebook .\",\n",
      "    \"course\": \"data-engineering-zoomcamp\",\n",
      "    \"_id\": 322\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\\nSolution:\\nAdd `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\",\n",
      "    \"section\": \"Module 4: analytics engineering with dbt\",\n",
      "    \"question\": \"DBT - Error: No module named 'pytz' while setting up dbt with docker\",\n",
      "    \"course\": \"data-engineering-zoomcamp\",\n",
      "    \"_id\": 299\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\\n` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\\nexport PYTHONPATH=\\u201d${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}\\u201d\\nMake sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\\nFor instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\\nThen the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\\\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\\\"` appropriately.\\nAdditionally, you can check for the version of \\u2018py4j\\u2019 of the spark you\\u2019re using from here and update as mentioned above.\\n~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\",\n",
      "    \"section\": \"Module 5: pyspark\",\n",
      "    \"question\": \"Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\",\n",
      "    \"course\": \"data-engineering-zoomcamp\",\n",
      "    \"_id\": 323\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"Issue:\\ne\\u2026\\nSolution:\\npip install psycopg2-binary\\nIf you already have it, you might need to update it:\\npip install psycopg2-binary --upgrade\\nOther methods, if the above fails:\\nif you are getting the \\u201c ModuleNotFoundError: No module named 'psycopg2' \\u201c error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\\nFirst uninstall the psycopg package\\nThen update conda or pip\\nThen install psycopg again using pip.\\nif you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\",\n",
      "    \"section\": \"Module 1: Docker and Terraform\",\n",
      "    \"question\": \"Postgres - ModuleNotFoundError: No module named 'psycopg2'\",\n",
      "    \"course\": \"data-engineering-zoomcamp\",\n",
      "    \"_id\": 112\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"create_engine('postgresql://root:root@localhost:5432/ny_taxi')  I get the error \\\"TypeError: 'module' object is not callable\\\"\\nSolution:\\nconn_string = \\\"postgresql+psycopg://root:root@localhost:5432/ny_taxi\\\"\\nengine = create_engine(conn_string)\",\n",
      "    \"section\": \"Module 1: Docker and Terraform\",\n",
      "    \"question\": \"Python - SQLALchemy - TypeError 'module' object is not callable\",\n",
      "    \"course\": \"data-engineering-zoomcamp\",\n",
      "    \"_id\": 124\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "search_results = json.dumps(results, indent=2)\n",
    "print(search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "db2a93cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_messages.append(call)\n",
    "\n",
    "chat_messages.append({\n",
    "    \"type\": \"function_call_output\",\n",
    "    \"call_id\": call.call_id,\n",
    "    \"output\": search_results,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "07305dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.responses.create(\n",
    "    model='gpt-4o-mini',\n",
    "    input=chat_messages,\n",
    "    tools=tools\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "54b01e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To excel in Module 1 of your course, here are some tips based on the content and common issues faced:\n",
      "\n",
      "1. **Understand the Requirements**: Make sure you thoroughly read the module instructions and know what tools (like Docker and PostgreSQL) you need to have installed.\n",
      "\n",
      "2. **Install Dependencies Properly**: If you encounter errors (like `ModuleNotFoundError: No module named 'psycopg2'`), ensure you've installed all required packages correctly:\n",
      "   - Use `pip install psycopg2-binary` to install the psycopg2 package.\n",
      "   - If you continue to face issues, try updating your installation with `pip install psycopg2-binary --upgrade`.\n",
      "\n",
      "3. **Follow Docker Setup Instructions Carefully**: If you’re using Docker, follow the provided setup instructions in detail, ensuring that all commands execute successfully.\n",
      "\n",
      "4. **Practice SQL Alchemy**: Familiarize yourself with SQL Alchemy usage, such as connection strings. For example, use:\n",
      "   ```python\n",
      "   conn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\n",
      "   engine = create_engine(conn_string)\n",
      "   ```\n",
      "\n",
      "5. **Engage with the Course Community**: If you encounter problems, don't hesitate to ask questions in forums or study groups. Engaging with peers can provide valuable insights.\n",
      "\n",
      "6. **Hands-On Practice**: Try to implement the concepts practically as much as possible. Set up your local environment and connect with PostgreSQL using Docker.\n",
      "\n",
      "7. **Stay Organized**: Keep your files and projects organized for easy reference and management.\n",
      "\n",
      "By following these suggestions and actively participating in the provided resources, you'll enhance your chances of doing well in Module 1. Good luck!\n"
     ]
    }
   ],
   "source": [
    "r = response.output[0]\n",
    "print(r.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b6160138",
   "metadata": {},
   "outputs": [],
   "source": [
    "developer_prompt = \"\"\"\n",
    "You're a course teaching assistant. \n",
    "You're given a question from a course student and your task is to answer it.\n",
    "If you look up something in FAQ, convert the student question into multiple queries.\n",
    "\"\"\".strip()\n",
    "\n",
    "chat_messages = [\n",
    "    {\"role\": \"developer\", \"content\": developer_prompt},\n",
    "    {\"role\": \"user\", \"content\": question}\n",
    "]\n",
    "\n",
    "response = client.responses.create(\n",
    "    model='gpt-4o-mini',\n",
    "    input=chat_messages,\n",
    "    tools=tools\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7a42c80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_call(tool_call_response):\n",
    "    function_name = tool_call_response.name\n",
    "    arguments = json.loads(tool_call_response.arguments)\n",
    "\n",
    "    f = globals()[function_name]\n",
    "    result = f(**arguments)\n",
    "\n",
    "    return {\n",
    "        \"type\": \"function_call_output\",\n",
    "        \"call_id\": tool_call_response.call_id,\n",
    "        \"output\": json.dumps(result, indent=2),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "214b7ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function_call\n",
      "function_call\n",
      "function_call\n"
     ]
    }
   ],
   "source": [
    "for entry in response.output:\n",
    "    chat_messages.append(entry)\n",
    "    print(entry.type)\n",
    "\n",
    "    if entry.type == 'function_call':      \n",
    "        result = do_call(entry)\n",
    "        chat_messages.append(result)\n",
    "    elif entry.type == 'message':\n",
    "        print(entry.text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "08177c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "message\n",
      "\n",
      "To excel in Module 1, here are some strategies and tips:\n",
      "\n",
      "### Key Strategies for Success:\n",
      "\n",
      "1. **Understand the Basics**: Make sure you have a solid grasp of the foundational concepts related to Docker and Terraform, as these are crucial for the module.\n",
      "\n",
      "2. **Hands-On Practice**: Engage with practical exercises. Set up your local environment using Docker. Follow the guides and instructions carefully to avoid common pitfalls.\n",
      "\n",
      "3. **Troubleshoot Common Errors**:\n",
      "   - **SQLAlchemy Issues**:\n",
      "     - If you encounter a `TypeError`: Ensure your connection string is formatted correctly. Use:\n",
      "       ```python\n",
      "       conn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\n",
      "       engine = create_engine(conn_string)\n",
      "       ```\n",
      "     - For `No module named 'psycopg2'`: Install it via pip:\n",
      "       ```\n",
      "       pip install psycopg2-binary\n",
      "       ```\n",
      "       If issues persist, consider updating or reinstalling the package.\n",
      "\n",
      "4. **Utilize Community Resources**: Engage with forums and discussion boards. Sharing your challenges and solutions can enhance your understanding and help others.\n",
      "\n",
      "5. **Keep Up with Assignments**: Regularly complete and review assignments to reinforce your learning.\n",
      "\n",
      "6. **Stay Organized**: Create notes summarizing key points from the module to help during revision.\n",
      "\n",
      "### Additional Tips:\n",
      "\n",
      "- **Debugging Environment**: Familiarize yourself with debugging tools and common errors related to Docker and SQLAlchemy.\n",
      "- **Learning Resources**: Refer to course materials, tutorials, and recommended readings to deepen your comprehension.\n",
      "- **Collaborate with Peers**: Work with classmates on projects or study sessions, as this can provide different perspectives and clarify understanding.\n",
      "\n",
      "By following these strategies and leveraging available resources, you can effectively enhance your performance in Module 1!\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model='gpt-4o-mini',\n",
    "    input=chat_messages,\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "for entry in response.output:\n",
    "    chat_messages.append(entry)\n",
    "    print(entry.type)\n",
    "    print()\n",
    "\n",
    "    if entry.type == 'function_call':      \n",
    "        result = do_call(entry)\n",
    "        chat_messages.append(result)\n",
    "    elif entry.type == 'message':\n",
    "        print(entry.content[0].text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "10399180",
   "metadata": {},
   "outputs": [],
   "source": [
    "developer_prompt = \"\"\"\n",
    "You're a course teaching assistant. \n",
    "You're given a question from a course student and your task is to answer it.\n",
    "\n",
    "Use FAQ if your own knowledge is not sufficient to answer the question.\n",
    "When using FAQ, perform deep topic exploration: make one request to FAQ,\n",
    "and then based on the results, make more requests.\n",
    "\n",
    "At the end of each response, ask the user a follow up question based on your answer.\n",
    "\"\"\".strip()\n",
    "\n",
    "chat_messages = [\n",
    "    {\"role\": \"developer\", \"content\": developer_prompt},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae070809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function_call: ResponseFunctionToolCall(arguments='{\"query\":\"how to do best in module 1\"}', call_id='call_N4GvJc29JgHNo5tNyMwLumZg', name='search', type='function_call', id='fc_6877ebc07a9c81998af14a3034e222be0b424739f391ba46', status='completed')\n",
      "\n",
      "function_call: ResponseFunctionToolCall(arguments='{\"query\":\"tips for success in module 1 docker and terraform\"}', call_id='call_XdX8WuEusrJdr9YH0VTMq4wk', name='search', type='function_call', id='fc_6877ebc2cc408199bc94cddddc048c1a0b424739f391ba46', status='completed')\n",
      "\n",
      "To excel in Module 1, which focuses on Docker and Terraform, here are some key tips based on information gathered:\n",
      "\n",
      "1. **Follow Best Practices for Docker**:\n",
      "   - Store all code in your default Linux distro to maximize file system performance. This is particularly important for users on Windows 10 or Windows 11, as Docker runs on WSL2 by default.\n",
      "\n",
      "2. **Ensure Proper Setup for Terraform**:\n",
      "   - Always navigate to the correct working directory that contains your Terraform configuration files before running commands like `terraform init`.\n",
      "   - Make sure you have the proper access permissions in Google Cloud Platform (GCP) if you're using Terraform to create resources. Use your Project ID, not the name displayed on the GCP Dashboard.\n",
      "\n",
      "3. **Installation and Configuration**:\n",
      "   - If you're using a virtual machine or Docker, make sure all required software, like `psycopg2` for SQLAlchemy, is installed.\n",
      "   - Review the Terraform and Docker documentation for platform-specific setup, especially if you are on Windows Subsystem for Linux.\n",
      "\n",
      "4. **Troubleshoot Common Errors**:\n",
      "   - Be aware of common errors in Terraform, such as being locked out of the state or permission issues while creating buckets on GCP.\n",
      "   - Check your network settings, especially if you are using a VPN, which might prevent access to required services.\n",
      "\n",
      "5. **Utilize Resources**:\n",
      "   - Review GitHub and tech community resources relevant to Docker and Terraform. There might be community-contributed guides that can provide insights tailored to your setup.\n",
      "\n",
      "By applying these strategies, you can improve your understanding and performance in Module 1.\n",
      "\n",
      "### Follow-Up Question:\n",
      "What specific topics or tools within Docker and Terraform would you like more help with?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "while True: # main Q&A loop\n",
    "    question = input() # How do I do my best for module 1?\n",
    "    if question == 'stop':\n",
    "        break\n",
    "\n",
    "    message = {\"role\": \"user\", \"content\": question}\n",
    "    chat_messages.append(message)\n",
    "\n",
    "    while True: # request-response loop - query API till get a message\n",
    "        response = client.responses.create(\n",
    "            model='gpt-4o-mini',\n",
    "            input=chat_messages,\n",
    "            tools=tools\n",
    "        )\n",
    "\n",
    "        has_messages = False\n",
    "        \n",
    "        for entry in response.output:\n",
    "            chat_messages.append(entry)\n",
    "        \n",
    "            if entry.type == 'function_call':      \n",
    "                print('function_call:', entry)\n",
    "                print()\n",
    "                result = do_call(entry)\n",
    "                chat_messages.append(result)\n",
    "            elif entry.type == 'message':\n",
    "                print(entry.content[0].text)\n",
    "                print()\n",
    "                has_messages = True\n",
    "\n",
    "        if has_messages:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4ff47109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shorten(text, max_length=50):\n",
    "    if len(text) <= max_length:\n",
    "        return text\n",
    "\n",
    "def display_function_call(entry, result):\n",
    "    call_html = f\"\"\"\n",
    "        <details>\n",
    "        <summary>Function call: <tt>{entry.name}({shorten(entry.arguments)})</tt></summary>\n",
    "        <div>\n",
    "            <b>Call</b>\n",
    "            <pre>{entry}</pre>\n",
    "        </div>\n",
    "        <div>\n",
    "            <b>Output</b>\n",
    "            <pre>{result['output']}</pre>\n",
    "        </div>\n",
    "        \n",
    "        </details>\n",
    "    \"\"\"\n",
    "    display(HTML(call_html))\n",
    "\n",
    "def display_response(entry):\n",
    "    response_html = markdown.markdown(entry.content[0].text)\n",
    "    html = f\"\"\"\n",
    "        <div>\n",
    "            <div><b>Assistant:</b></div>\n",
    "            <div>{response_html}</div>\n",
    "        </div>\n",
    "    \"\"\"\n",
    "    display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6bec6ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat ended.\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "import markdown # pip install markdown\n",
    "\n",
    "\n",
    "developer_prompt = \"\"\"\n",
    "You're a course teaching assistant. \n",
    "You're given a question from a course student and your task is to answer it.\n",
    "\n",
    "Use FAQ if your own knowledge is not sufficient to answer the question.\n",
    "\n",
    "At the end of each response, ask the user a follow up question based on your answer.\n",
    "\"\"\".strip()\n",
    "\n",
    "chat_messages = [\n",
    "    {\"role\": \"developer\", \"content\": developer_prompt},\n",
    "]\n",
    "\n",
    "# Chat loop\n",
    "while True:\n",
    "    question = input() # How do I do my best for module 1?\n",
    "    \n",
    "    if question.strip().lower() == 'stop':\n",
    "        print(\"Chat ended.\")\n",
    "        break\n",
    "    print()\n",
    "\n",
    "    message = {\"role\": \"user\", \"content\": question}\n",
    "    chat_messages.append(message)\n",
    "\n",
    "    while True:  # inner request loop\n",
    "        response = client.responses.create(\n",
    "            model='gpt-4o-mini',\n",
    "            input=chat_messages,\n",
    "            tools=tools\n",
    "        )\n",
    "\n",
    "        has_messages = False\n",
    "\n",
    "        for entry in response.output:\n",
    "            chat_messages.append(entry)\n",
    "\n",
    "            if entry.type == \"function_call\":\n",
    "                result = do_call(entry)\n",
    "                chat_messages.append(result)\n",
    "                display_function_call(entry, result)\n",
    "\n",
    "            elif entry.type == \"message\":\n",
    "                display_response(entry)\n",
    "                has_messages = True\n",
    "\n",
    "        if has_messages:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0bb30472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_entry(question, answer):\n",
    "    doc = {\n",
    "        'question': question,\n",
    "        'text': answer,\n",
    "        'section': 'user added',\n",
    "        'course': 'data-engineering-zoomcamp'\n",
    "    }\n",
    "    index.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "99f972ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_entry_description = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"add_entry\",\n",
    "    \"description\": \"Add an entry to the FAQ database\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"question\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question to be added to the FAQ database\",\n",
    "            },\n",
    "            \"answer\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The answer to the question\",\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"question\", \"answer\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3e667bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-07-16 12:32:29--  https://raw.githubusercontent.com/alexeygrigorev/rag-agents-workshop/refs/heads/main/chat_assistant.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3485 (3.4K) [text/plain]\n",
      "Saving to: ‘chat_assistant.py’\n",
      "\n",
      "chat_assistant.py   100%[===================>]   3.40K  --.-KB/s    in 0.001s  \n",
      "\n",
      "2025-07-16 12:32:29 (3.71 MB/s) - ‘chat_assistant.py’ saved [3485/3485]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/alexeygrigorev/rag-agents-workshop/refs/heads/main/chat_assistant.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "43b3c2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chat_assistant\n",
    "\n",
    "tools = chat_assistant.Tools()\n",
    "tools.add_tool(search, search_tool)\n",
    "\n",
    "tools.get_tools()\n",
    "\n",
    "developer_prompt = \"\"\"\n",
    "You're a course teaching assistant. \n",
    "You're given a question from a course student and your task is to answer it.\n",
    "\n",
    "Use FAQ if your own knowledge is not sufficient to answer the question.\n",
    "\n",
    "At the end of each response, ask the user a follow up question based on your answer.\n",
    "\"\"\".strip()\n",
    "\n",
    "chat_interface = chat_assistant.ChatInterface()\n",
    "\n",
    "chat = chat_assistant.ChatAssistant(\n",
    "    tools=tools,\n",
    "    developer_prompt=developer_prompt,\n",
    "    chat_interface=chat_interface,\n",
    "    client=client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f9b7653a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>¡Hola! ¿Cómo puedo ayudarte hoy?</p></div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>search({\"query\":\"certificación curso\"})</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>ResponseFunctionToolCall(arguments='{\"query\":\"certificación curso\"}', call_id='call_letXcVAflVuBusxTtiuKdsgJ', name='search', type='function_call', id='fc_6877f28ae7788199bbc26104313af0270a23c1bd77af099f', status='completed')</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>[]</pre>\n",
       "            </div>\n",
       "            \n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>Para certificarte en el curso, normalmente necesitas cumplir con ciertos requisitos, como completar todas las asignaciones, participar en las actividades y aprobar el examen final, si lo hay. Te recomiendo revisar la guía del curso o los materiales proporcionados para obtener información específica sobre las pautas de certificación.</p>\n",
       "<p>¿Tienes alguna pregunta específica sobre el proceso de certificación?</p></div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat ended.\n"
     ]
    }
   ],
   "source": [
    "chat.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ae431105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'name': 'search',\n",
       "  'description': 'Search the FAQ database',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'query': {'type': 'string',\n",
       "     'description': 'Search query text to look up in the course FAQ.'}},\n",
       "   'required': ['query'],\n",
       "   'additionalProperties': False}},\n",
       " {'type': 'function',\n",
       "  'name': 'add_entry',\n",
       "  'description': 'Add an entry to the FAQ database',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'question': {'type': 'string',\n",
       "     'description': 'The question to be added to the FAQ database'},\n",
       "    'answer': {'type': 'string', 'description': 'The answer to the question'}},\n",
       "   'required': ['question', 'answer'],\n",
       "   'additionalProperties': False}}]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools.add_tool(add_entry, add_entry_description)\n",
    "tools.get_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "321fb99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>search({\"query\":\"Install the new version of kestra\"})</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>ResponseFunctionToolCall(arguments='{\"query\":\"Install the new version of kestra\"}', call_id='call_nv0ebNsqwZTJ5YwVFt3emuvE', name='search', type='function_call', id='fc_6877f2eeedc0819b8f514dd6c0e7fbc505a4a040839672f1', status='completed')</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>[\n",
       "  {\n",
       "    \"text\": \"for windows if you having trouble install SDK try follow these steps on the link, if you getting this error:\\nThese credentials will be used by any library that requests Application Default Credentials (ADC).\\nWARNING:\\nCannot find a quota project to add to ADC. You might receive a \\\"quota exceeded\\\" or \\\"API not enabled\\\" error. Run $ gcloud auth application-default set-quota-project to add a quota project.\\nFor me:\\nI reinstalled the sdk using unzip file \\u201cinstall.bat\\u201d,\\nafter successfully checking gcloud version,\\nrun gcloud init to set up project before\\nyou run gcloud auth application-default login\\nhttps://github.com/DataTalksClub/data-engineering-zoomcamp/blob/main/week_1_basics_n_setup/1_terraform_gcp/windows.md\\nGCP VM - I cannot get my Virtual Machine to start because GCP has no resources.\\nClick on your VM\\nCreate an image of your VM\\nOn the page of the image, tell GCP to create a new VM instance via the image\\nOn the settings page, change the location\",\n",
       "    \"section\": \"Module 1: Docker and Terraform\",\n",
       "    \"question\": \"GCP - Windows Google Cloud SDK install issue:gcp\",\n",
       "    \"course\": \"data-engineering-zoomcamp\",\n",
       "    \"_id\": 134\n",
       "  },\n",
       "  {\n",
       "    \"text\": \"If below does not work, then download the latest available py4j version with\\nconda install -c conda-forge py4j\\nTake care of the latest version number in the website to replace appropriately.\\nNow add\\nexport PYTHONPATH=\\\"${SPARK_HOME}/python/:$PYTHONPATH\\\"\\nexport PYTHONPATH=\\\"${SPARK_HOME}/python/lib/py4j-0.10.9.7-src.zip:$PYTHONPATH\\\"\\nin your  .bashrc file.\",\n",
       "    \"section\": \"Module 5: pyspark\",\n",
       "    \"question\": \"Py4J Error - ModuleNotFoundError: No module named 'py4j' (Solve with latest version)\",\n",
       "    \"course\": \"data-engineering-zoomcamp\",\n",
       "    \"_id\": 324\n",
       "  },\n",
       "  {\n",
       "    \"text\": \"Change the hadoop version to 3.0.1.Replace all the files in the local hadoop bin folder with the files in this repo:  winutils/hadoop-3.0.1/bin at master \\u00b7 cdarlint/winutils (github.com)\\nIf this does not work try to change other versions found in this repository.\\nFor more information please see this link: This version of %1 is not compatible with the version of Windows you're running \\u00b7 Issue #20 \\u00b7 cdarlint/winutils (github.com)\",\n",
       "    \"section\": \"Module 5: pyspark\",\n",
       "    \"question\": \"Java.io.IOException. Cannot run program \\u201cC:\\\\hadoop\\\\bin\\\\winutils.exe\\u201d. CreateProcess error=216, This version of 1% is not compatible with the version of Windows you are using.\",\n",
       "    \"course\": \"data-engineering-zoomcamp\",\n",
       "    \"_id\": 355\n",
       "  },\n",
       "  {\n",
       "    \"text\": \"You may have this error:\\nRetrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.u\\nrllib3.connection.HTTPSConnection object at 0x7efe331cf790>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')':\\n/simple/pandas/\\nPossible solution might be:\\n$ winpty docker run -it --dns=8.8.8.8 --entrypoint=bash python:3.9\",\n",
       "    \"section\": \"Module 1: Docker and Terraform\",\n",
       "    \"question\": \"Docker - Cannot pip install on Docker container (Windows)\",\n",
       "    \"course\": \"data-engineering-zoomcamp\",\n",
       "    \"_id\": 60\n",
       "  },\n",
       "  {\n",
       "    \"text\": \"Solution:\\nCheck if you\\u2019re on the Developer Plan. As per the prerequisites, you'll need to be enrolled in the Team Plan or Enterprise Plan to set up a CI Job in dbt Cloud.\\nSo If you're on the Developer Plan, you'll need to upgrade to utilise CI Jobs.\\nNote from another user: I\\u2019m in the Team Plan (trial period) but the option is still disabled. What worked for me instead was this. It works for the Developer (free) plan.\",\n",
       "    \"section\": \"Module 4: analytics engineering with dbt\",\n",
       "    \"question\": \"dbt job - Triggered by pull requests is disabled when I try to create a new Continuous Integration job in dbt cloud.\",\n",
       "    \"course\": \"data-engineering-zoomcamp\",\n",
       "    \"_id\": 246\n",
       "  }\n",
       "]</pre>\n",
       "            </div>\n",
       "            \n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>It seems there's no explicit FAQ entry regarding the installation of the new version of Kestra. However, generally, you can install or update Kestra by following these basic steps:</p>\n",
       "<ol>\n",
       "<li><strong>Download the latest version</strong> from the <a href=\"https://github.com/kestra-io/kestra/releases\">Kestra GitHub releases page</a>.</li>\n",
       "<li><strong>Extract the files and navigate to the directory</strong> where you extracted Kestra.</li>\n",
       "<li><strong>Run the installation command</strong> according to the specific environment you're using (Docker, Kubernetes, etc.).</li>\n",
       "<li><strong>Follow any additional setup instructions</strong> for your specific platform as detailed in the documentation.</li>\n",
       "</ol>\n",
       "<p>If you can provide more details about your environment (for example, whether you are using Docker or running it locally), I could give you more specific instructions.</p>\n",
       "<p>What environment are you using to install Kestra?</p></div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>add_entry({\"question\":\"How do I install the new version o...)</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>ResponseFunctionToolCall(arguments='{\"question\":\"How do I install the new version of Kestra?\",\"answer\":\"1. **Download the latest version** from the [Kestra GitHub releases page](https://github.com/kestra-io/kestra/releases). 2. **Extract the files and navigate to the directory** where you extracted Kestra. 3. **Run the installation command** according to the specific environment you\\'re using (Docker, Kubernetes, etc.). 4. **Follow any additional setup instructions** for your specific platform as detailed in the documentation.\"}', call_id='call_TewPrpq7BLb7KPgFsYfQ6PUs', name='add_entry', type='function_call', id='fc_6877f30be024819b95d4de1c71bb3b7705a4a040839672f1', status='completed')</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>null</pre>\n",
       "            </div>\n",
       "            \n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>I've added the installation instructions for the new version of Kestra to the FAQ. If you need assistance with anything else or have more questions, feel free to ask!</p>\n",
       "<p>What specific features or functionalities are you looking to explore in the new version of Kestra?</p></div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat ended.\n"
     ]
    }
   ],
   "source": [
    "chat.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3fd09fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'How do I install the new version of Kestra?',\n",
       " 'text': \"1. **Download the latest version** from the [Kestra GitHub releases page](https://github.com/kestra-io/kestra/releases). 2. **Extract the files and navigate to the directory** where you extracted Kestra. 3. **Run the installation command** according to the specific environment you're using (Docker, Kubernetes, etc.). 4. **Follow any additional setup instructions** for your specific platform as detailed in the documentation.\",\n",
       " 'section': 'user added',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.docs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8550dc38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
